{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment: Compresive Strength Concrete Problem\n",
    "\n",
    "\n",
    "### Abstract: \n",
    "\n",
    "Concrete is the most important material in civil engineering. The concrete compressive strength (concrete strength to bear the load) is a highly nonlinear function of age and ingredients.  <br><br>\n",
    "\n",
    "<table border=\"1\"  cellpadding=\"6\" bordercolor=\"red\">\n",
    "\t<tbody>\n",
    "        <tr>\n",
    "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Data Set Characteristics:&nbsp;&nbsp;</b></p></td>\n",
    "\t\t<td><p class=\"normal\">Multivariate</p></td>\n",
    "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Number of Instances:</b></p></td>\n",
    "\t\t<td><p class=\"normal\">1030</p></td>\n",
    "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Area:</b></p></td>\n",
    "\t\t<td><p class=\"normal\">Physical</p></td>\n",
    "        </tr>\n",
    "     </tbody>\n",
    "    </table>\n",
    "<table border=\"1\" cellpadding=\"6\">\n",
    "    <tbody>\n",
    "        <tr>\n",
    "            <td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Attribute Characteristics:</b></p></td>\n",
    "            <td><p class=\"normal\">Real</p></td>\n",
    "            <td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Number of Attributes:</b></p></td>\n",
    "            <td><p class=\"normal\">9</p></td>\n",
    "            <td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Date Donated</b></p></td>\n",
    "            <td><p class=\"normal\">2007-08-03</p></td>\n",
    "        </tr>\n",
    "     </tbody>\n",
    "    </table>\n",
    "<table border=\"1\" cellpadding=\"6\">\t\n",
    "    <tbody>\n",
    "    <tr>\n",
    "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Associated Tasks:</b></p></td>\n",
    "\t\t<td><p class=\"normal\">Regression</p></td>\n",
    "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Missing Values?</b></p></td>\n",
    "\t\t<td><p class=\"normal\">N/A</p></td>\n",
    "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Number of Web Hits:</b></p></td>\n",
    "\t\t<td><p class=\"normal\">231464</p></td>\n",
    "\t</tr>\n",
    "    </tbody>\n",
    "    </table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Description:\n",
    "| Features Name | Data Type | Measurement | Description |\n",
    "| -- | -- | -- | -- |\n",
    "Cement (component 1) | quantitative | kg in a m3 mixture | Input Variable\n",
    "Blast Furnace Slag (component 2) | quantitative | kg in a m3 mixture | Input Variable\n",
    "Fly Ash (component 3) | quantitative | kg in a m3 mixture | Input Variable\n",
    "Water (component 4) | quantitative | kg in a m3 mixture | Input Variable\n",
    "Superplasticizer (component 5) | quantitative | kg in a m3 mixture | Input Variable\n",
    "Coarse Aggregate (component 6) | quantitative | kg in a m3 mixture | Input Variable\n",
    "Fine Aggregate (component 7) | quantitative | kg in a m3 mixture | Input Variable\n",
    "Age | quantitative | Day (1~365) | Input Variable\n",
    "Concrete compressive strength | quantitative | MPa | Output Variable\n",
    "\n",
    "### WORKFLOW :\n",
    "- Load Data\n",
    "- Check Missing Values ( If Exist ; Fill each record with mean of its feature )\n",
    "- Standardized the Input Variables. **Hint**: Centeralized the data\n",
    "- Split into 50% Training(Samples,Labels) , 30% Test(Samples,Labels) and 20% Validation Data(Samples,Labels).\n",
    "- Model : input Layer (No. of features ), 3 hidden layers including 10,8,6 unit & Output Layer with activation function relu/tanh (check by experiment).\n",
    "- Compilation Step (Note : Its a Regression problem , select loss , metrics according to it)\n",
    "- Train the Model with Epochs (100) and validate it\n",
    "- If the model gets overfit tune your model by changing the units , No. of layers , activation function , epochs , add dropout layer or add Regularizer according to the need .\n",
    "- Evaluation Step\n",
    "- Prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data:\n",
    "[Click Here to Download DataSet](https://github.com/ramsha275/ML_Datasets/blob/main/compresive_strength_concrete.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam, SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data= pd.read_csv('compresive_strength_concrete.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement (component 1)(kg in a m^3 mixture)</th>\n",
       "      <th>Blast Furnace Slag (component 2)(kg in a m^3 mixture)</th>\n",
       "      <th>Fly Ash (component 3)(kg in a m^3 mixture)</th>\n",
       "      <th>Water  (component 4)(kg in a m^3 mixture)</th>\n",
       "      <th>Superplasticizer (component 5)(kg in a m^3 mixture)</th>\n",
       "      <th>Coarse Aggregate  (component 6)(kg in a m^3 mixture)</th>\n",
       "      <th>Fine Aggregate (component 7)(kg in a m^3 mixture)</th>\n",
       "      <th>Age (day)</th>\n",
       "      <th>Concrete compressive strength(MPa, megapascals)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>79.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>61.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "      <td>40.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "      <td>41.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>360</td>\n",
       "      <td>44.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025</th>\n",
       "      <td>276.4</td>\n",
       "      <td>116.0</td>\n",
       "      <td>90.3</td>\n",
       "      <td>179.6</td>\n",
       "      <td>8.9</td>\n",
       "      <td>870.1</td>\n",
       "      <td>768.3</td>\n",
       "      <td>28</td>\n",
       "      <td>44.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026</th>\n",
       "      <td>322.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>115.6</td>\n",
       "      <td>196.0</td>\n",
       "      <td>10.4</td>\n",
       "      <td>817.9</td>\n",
       "      <td>813.4</td>\n",
       "      <td>28</td>\n",
       "      <td>31.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1027</th>\n",
       "      <td>148.5</td>\n",
       "      <td>139.4</td>\n",
       "      <td>108.6</td>\n",
       "      <td>192.7</td>\n",
       "      <td>6.1</td>\n",
       "      <td>892.4</td>\n",
       "      <td>780.0</td>\n",
       "      <td>28</td>\n",
       "      <td>23.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1028</th>\n",
       "      <td>159.1</td>\n",
       "      <td>186.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>175.6</td>\n",
       "      <td>11.3</td>\n",
       "      <td>989.6</td>\n",
       "      <td>788.9</td>\n",
       "      <td>28</td>\n",
       "      <td>32.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1029</th>\n",
       "      <td>260.9</td>\n",
       "      <td>100.5</td>\n",
       "      <td>78.3</td>\n",
       "      <td>200.6</td>\n",
       "      <td>8.6</td>\n",
       "      <td>864.5</td>\n",
       "      <td>761.5</td>\n",
       "      <td>28</td>\n",
       "      <td>32.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1030 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Cement (component 1)(kg in a m^3 mixture)  \\\n",
       "0                                         540.0   \n",
       "1                                         540.0   \n",
       "2                                         332.5   \n",
       "3                                         332.5   \n",
       "4                                         198.6   \n",
       "...                                         ...   \n",
       "1025                                      276.4   \n",
       "1026                                      322.2   \n",
       "1027                                      148.5   \n",
       "1028                                      159.1   \n",
       "1029                                      260.9   \n",
       "\n",
       "      Blast Furnace Slag (component 2)(kg in a m^3 mixture)  \\\n",
       "0                                                   0.0       \n",
       "1                                                   0.0       \n",
       "2                                                 142.5       \n",
       "3                                                 142.5       \n",
       "4                                                 132.4       \n",
       "...                                                 ...       \n",
       "1025                                              116.0       \n",
       "1026                                                0.0       \n",
       "1027                                              139.4       \n",
       "1028                                              186.7       \n",
       "1029                                              100.5       \n",
       "\n",
       "      Fly Ash (component 3)(kg in a m^3 mixture)  \\\n",
       "0                                            0.0   \n",
       "1                                            0.0   \n",
       "2                                            0.0   \n",
       "3                                            0.0   \n",
       "4                                            0.0   \n",
       "...                                          ...   \n",
       "1025                                        90.3   \n",
       "1026                                       115.6   \n",
       "1027                                       108.6   \n",
       "1028                                         0.0   \n",
       "1029                                        78.3   \n",
       "\n",
       "      Water  (component 4)(kg in a m^3 mixture)  \\\n",
       "0                                         162.0   \n",
       "1                                         162.0   \n",
       "2                                         228.0   \n",
       "3                                         228.0   \n",
       "4                                         192.0   \n",
       "...                                         ...   \n",
       "1025                                      179.6   \n",
       "1026                                      196.0   \n",
       "1027                                      192.7   \n",
       "1028                                      175.6   \n",
       "1029                                      200.6   \n",
       "\n",
       "      Superplasticizer (component 5)(kg in a m^3 mixture)  \\\n",
       "0                                                   2.5     \n",
       "1                                                   2.5     \n",
       "2                                                   0.0     \n",
       "3                                                   0.0     \n",
       "4                                                   0.0     \n",
       "...                                                 ...     \n",
       "1025                                                8.9     \n",
       "1026                                               10.4     \n",
       "1027                                                6.1     \n",
       "1028                                               11.3     \n",
       "1029                                                8.6     \n",
       "\n",
       "      Coarse Aggregate  (component 6)(kg in a m^3 mixture)  \\\n",
       "0                                                1040.0      \n",
       "1                                                1055.0      \n",
       "2                                                 932.0      \n",
       "3                                                 932.0      \n",
       "4                                                 978.4      \n",
       "...                                                 ...      \n",
       "1025                                              870.1      \n",
       "1026                                              817.9      \n",
       "1027                                              892.4      \n",
       "1028                                              989.6      \n",
       "1029                                              864.5      \n",
       "\n",
       "      Fine Aggregate (component 7)(kg in a m^3 mixture)  Age (day)  \\\n",
       "0                                                 676.0         28   \n",
       "1                                                 676.0         28   \n",
       "2                                                 594.0        270   \n",
       "3                                                 594.0        365   \n",
       "4                                                 825.5        360   \n",
       "...                                                 ...        ...   \n",
       "1025                                              768.3         28   \n",
       "1026                                              813.4         28   \n",
       "1027                                              780.0         28   \n",
       "1028                                              788.9         28   \n",
       "1029                                              761.5         28   \n",
       "\n",
       "      Concrete compressive strength(MPa, megapascals)   \n",
       "0                                                79.99  \n",
       "1                                                61.89  \n",
       "2                                                40.27  \n",
       "3                                                41.05  \n",
       "4                                                44.30  \n",
       "...                                                ...  \n",
       "1025                                             44.28  \n",
       "1026                                             31.18  \n",
       "1027                                             23.70  \n",
       "1028                                             32.77  \n",
       "1029                                             32.40  \n",
       "\n",
       "[1030 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = (data.loc[:, data.columns != 'Concrete compressive strength(MPa, megapascals) '])\n",
    "y = (data.loc[:, data.columns == 'Concrete compressive strength(MPa, megapascals) '])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardized the Input Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data standardization with  sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "x=x.copy()\n",
    "\n",
    "num_cols = ['Cement (component 1)(kg in a m^3 mixture)',\n",
    "       'Blast Furnace Slag (component 2)(kg in a m^3 mixture)',\n",
    "       'Fly Ash (component 3)(kg in a m^3 mixture)',\n",
    "       'Water  (component 4)(kg in a m^3 mixture)',\n",
    "       'Superplasticizer (component 5)(kg in a m^3 mixture)',\n",
    "       'Coarse Aggregate  (component 6)(kg in a m^3 mixture)',\n",
    "       'Fine Aggregate (component 7)(kg in a m^3 mixture)', 'Age (day)']\n",
    "for i in num_cols:\n",
    "    \n",
    "    scale = StandardScaler().fit(x[[i]])\n",
    "    \n",
    "    x[i] = scale.transform(x[[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement (component 1)(kg in a m^3 mixture)</th>\n",
       "      <th>Blast Furnace Slag (component 2)(kg in a m^3 mixture)</th>\n",
       "      <th>Fly Ash (component 3)(kg in a m^3 mixture)</th>\n",
       "      <th>Water  (component 4)(kg in a m^3 mixture)</th>\n",
       "      <th>Superplasticizer (component 5)(kg in a m^3 mixture)</th>\n",
       "      <th>Coarse Aggregate  (component 6)(kg in a m^3 mixture)</th>\n",
       "      <th>Fine Aggregate (component 7)(kg in a m^3 mixture)</th>\n",
       "      <th>Age (day)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.477915</td>\n",
       "      <td>-0.856888</td>\n",
       "      <td>-0.847144</td>\n",
       "      <td>-0.916764</td>\n",
       "      <td>-0.620448</td>\n",
       "      <td>0.863154</td>\n",
       "      <td>-1.217670</td>\n",
       "      <td>-0.279733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.477915</td>\n",
       "      <td>-0.856888</td>\n",
       "      <td>-0.847144</td>\n",
       "      <td>-0.916764</td>\n",
       "      <td>-0.620448</td>\n",
       "      <td>1.056164</td>\n",
       "      <td>-1.217670</td>\n",
       "      <td>-0.279733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.491425</td>\n",
       "      <td>0.795526</td>\n",
       "      <td>-0.847144</td>\n",
       "      <td>2.175461</td>\n",
       "      <td>-1.039143</td>\n",
       "      <td>-0.526517</td>\n",
       "      <td>-2.240917</td>\n",
       "      <td>3.553066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.491425</td>\n",
       "      <td>0.795526</td>\n",
       "      <td>-0.847144</td>\n",
       "      <td>2.175461</td>\n",
       "      <td>-1.039143</td>\n",
       "      <td>-0.526517</td>\n",
       "      <td>-2.240917</td>\n",
       "      <td>5.057677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.790459</td>\n",
       "      <td>0.678408</td>\n",
       "      <td>-0.847144</td>\n",
       "      <td>0.488793</td>\n",
       "      <td>-1.039143</td>\n",
       "      <td>0.070527</td>\n",
       "      <td>0.647884</td>\n",
       "      <td>4.978487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025</th>\n",
       "      <td>-0.045645</td>\n",
       "      <td>0.488235</td>\n",
       "      <td>0.564545</td>\n",
       "      <td>-0.092171</td>\n",
       "      <td>0.451410</td>\n",
       "      <td>-1.323005</td>\n",
       "      <td>-0.065893</td>\n",
       "      <td>-0.279733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026</th>\n",
       "      <td>0.392819</td>\n",
       "      <td>-0.856888</td>\n",
       "      <td>0.960068</td>\n",
       "      <td>0.676200</td>\n",
       "      <td>0.702626</td>\n",
       "      <td>-1.994680</td>\n",
       "      <td>0.496893</td>\n",
       "      <td>-0.279733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1027</th>\n",
       "      <td>-1.270088</td>\n",
       "      <td>0.759579</td>\n",
       "      <td>0.850635</td>\n",
       "      <td>0.521589</td>\n",
       "      <td>-0.017528</td>\n",
       "      <td>-1.036064</td>\n",
       "      <td>0.080107</td>\n",
       "      <td>-0.279733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1028</th>\n",
       "      <td>-1.168610</td>\n",
       "      <td>1.308065</td>\n",
       "      <td>-0.847144</td>\n",
       "      <td>-0.279579</td>\n",
       "      <td>0.853356</td>\n",
       "      <td>0.214641</td>\n",
       "      <td>0.191166</td>\n",
       "      <td>-0.279733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1029</th>\n",
       "      <td>-0.194033</td>\n",
       "      <td>0.308499</td>\n",
       "      <td>0.376945</td>\n",
       "      <td>0.891719</td>\n",
       "      <td>0.401166</td>\n",
       "      <td>-1.395062</td>\n",
       "      <td>-0.150748</td>\n",
       "      <td>-0.279733</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1030 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Cement (component 1)(kg in a m^3 mixture)  \\\n",
       "0                                      2.477915   \n",
       "1                                      2.477915   \n",
       "2                                      0.491425   \n",
       "3                                      0.491425   \n",
       "4                                     -0.790459   \n",
       "...                                         ...   \n",
       "1025                                  -0.045645   \n",
       "1026                                   0.392819   \n",
       "1027                                  -1.270088   \n",
       "1028                                  -1.168610   \n",
       "1029                                  -0.194033   \n",
       "\n",
       "      Blast Furnace Slag (component 2)(kg in a m^3 mixture)  \\\n",
       "0                                             -0.856888       \n",
       "1                                             -0.856888       \n",
       "2                                              0.795526       \n",
       "3                                              0.795526       \n",
       "4                                              0.678408       \n",
       "...                                                 ...       \n",
       "1025                                           0.488235       \n",
       "1026                                          -0.856888       \n",
       "1027                                           0.759579       \n",
       "1028                                           1.308065       \n",
       "1029                                           0.308499       \n",
       "\n",
       "      Fly Ash (component 3)(kg in a m^3 mixture)  \\\n",
       "0                                      -0.847144   \n",
       "1                                      -0.847144   \n",
       "2                                      -0.847144   \n",
       "3                                      -0.847144   \n",
       "4                                      -0.847144   \n",
       "...                                          ...   \n",
       "1025                                    0.564545   \n",
       "1026                                    0.960068   \n",
       "1027                                    0.850635   \n",
       "1028                                   -0.847144   \n",
       "1029                                    0.376945   \n",
       "\n",
       "      Water  (component 4)(kg in a m^3 mixture)  \\\n",
       "0                                     -0.916764   \n",
       "1                                     -0.916764   \n",
       "2                                      2.175461   \n",
       "3                                      2.175461   \n",
       "4                                      0.488793   \n",
       "...                                         ...   \n",
       "1025                                  -0.092171   \n",
       "1026                                   0.676200   \n",
       "1027                                   0.521589   \n",
       "1028                                  -0.279579   \n",
       "1029                                   0.891719   \n",
       "\n",
       "      Superplasticizer (component 5)(kg in a m^3 mixture)  \\\n",
       "0                                             -0.620448     \n",
       "1                                             -0.620448     \n",
       "2                                             -1.039143     \n",
       "3                                             -1.039143     \n",
       "4                                             -1.039143     \n",
       "...                                                 ...     \n",
       "1025                                           0.451410     \n",
       "1026                                           0.702626     \n",
       "1027                                          -0.017528     \n",
       "1028                                           0.853356     \n",
       "1029                                           0.401166     \n",
       "\n",
       "      Coarse Aggregate  (component 6)(kg in a m^3 mixture)  \\\n",
       "0                                              0.863154      \n",
       "1                                              1.056164      \n",
       "2                                             -0.526517      \n",
       "3                                             -0.526517      \n",
       "4                                              0.070527      \n",
       "...                                                 ...      \n",
       "1025                                          -1.323005      \n",
       "1026                                          -1.994680      \n",
       "1027                                          -1.036064      \n",
       "1028                                           0.214641      \n",
       "1029                                          -1.395062      \n",
       "\n",
       "      Fine Aggregate (component 7)(kg in a m^3 mixture)  Age (day)  \n",
       "0                                             -1.217670  -0.279733  \n",
       "1                                             -1.217670  -0.279733  \n",
       "2                                             -2.240917   3.553066  \n",
       "3                                             -2.240917   5.057677  \n",
       "4                                              0.647884   4.978487  \n",
       "...                                                 ...        ...  \n",
       "1025                                          -0.065893  -0.279733  \n",
       "1026                                           0.496893  -0.279733  \n",
       "1027                                           0.080107  -0.279733  \n",
       "1028                                           0.191166  -0.279733  \n",
       "1029                                          -0.150748  -0.279733  \n",
       "\n",
       "[1030 rows x 8 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.30, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(721, 8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##from keras import models\n",
    "from keras import layers\n",
    "def build_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(16, activation='relu',input_shape=(8,)))\n",
    "    model.add(layers.Dense(8, activation='relu'))\n",
    "    model.add(layers.Dense(6, activation='relu'))\n",
    "\n",
    "    model.add(layers.Dense(1, activation='tanh'))\n",
    "    model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "def build_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(16, activation='relu',input_shape=(8,)))\n",
    "    model.add(layers.Dense(4, activation='relu'))\n",
    "\n",
    "    model.add(layers.Dense(1, activation='linear'))\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing fold # 0\n",
      "Epoch 1/220\n",
      "34/34 [==============================] - 0s 13ms/step - loss: 1577.6923 - mae: 35.9318 - val_loss: 1606.6283 - val_mae: 36.2478\n",
      "Epoch 2/220\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 1566.3328 - mae: 35.7692 - val_loss: 1597.6021 - val_mae: 36.1208\n",
      "Epoch 3/220\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 1558.9620 - mae: 35.6538 - val_loss: 1589.4012 - val_mae: 35.9958\n",
      "Epoch 4/220\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 1548.2736 - mae: 35.4899 - val_loss: 1573.8323 - val_mae: 35.7684\n",
      "Epoch 5/220\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 1525.7948 - mae: 35.1787 - val_loss: 1545.6722 - val_mae: 35.3864\n",
      "Epoch 6/220\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1487.5392 - mae: 34.6863 - val_loss: 1499.7841 - val_mae: 34.7951\n",
      "Epoch 7/220\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 1437.0194 - mae: 34.0317 - val_loss: 1445.0159 - val_mae: 34.0794\n",
      "Epoch 8/220\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 1376.8676 - mae: 33.2443 - val_loss: 1378.0125 - val_mae: 33.1939\n",
      "Epoch 9/220\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 1304.0345 - mae: 32.2739 - val_loss: 1299.2147 - val_mae: 32.1252\n",
      "Epoch 10/220\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 1219.0383 - mae: 31.0966 - val_loss: 1206.6693 - val_mae: 30.8294\n",
      "Epoch 11/220\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 1122.0750 - mae: 29.7055 - val_loss: 1102.7690 - val_mae: 29.3285\n",
      "Epoch 12/220\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 1015.4414 - mae: 28.0957 - val_loss: 990.1168 - val_mae: 27.6164\n",
      "Epoch 13/220\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 903.0601 - mae: 26.2689 - val_loss: 874.1401 - val_mae: 25.7064\n",
      "Epoch 14/220\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 788.6143 - mae: 24.2660 - val_loss: 758.5956 - val_mae: 23.6071\n",
      "Epoch 15/220\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 677.2069 - mae: 22.1787 - val_loss: 651.8020 - val_mae: 21.6025\n",
      "Epoch 16/220\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 576.0573 - mae: 20.1306 - val_loss: 552.2659 - val_mae: 19.6583\n",
      "Epoch 17/220\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 484.2780 - mae: 18.2361 - val_loss: 471.1367 - val_mae: 17.9697\n",
      "Epoch 18/220\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 410.2630 - mae: 16.5891 - val_loss: 402.8679 - val_mae: 16.4820\n",
      "Epoch 19/220\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 350.5703 - mae: 15.1223 - val_loss: 351.5591 - val_mae: 15.2691\n",
      "Epoch 20/220\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 305.1588 - mae: 14.0443 - val_loss: 313.4757 - val_mae: 14.3872\n",
      "Epoch 21/220\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 272.2664 - mae: 13.1848 - val_loss: 285.2983 - val_mae: 13.7054\n",
      "Epoch 22/220\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 247.7378 - mae: 12.5638 - val_loss: 266.7208 - val_mae: 13.2274\n",
      "Epoch 23/220\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 231.0193 - mae: 12.1215 - val_loss: 251.2297 - val_mae: 12.8382\n",
      "Epoch 24/220\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 218.5764 - mae: 11.7946 - val_loss: 240.7565 - val_mae: 12.5593\n",
      "Epoch 25/220\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 209.4123 - mae: 11.5437 - val_loss: 232.5270 - val_mae: 12.3537\n",
      "Epoch 26/220\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 201.9682 - mae: 11.3542 - val_loss: 225.8962 - val_mae: 12.1825\n",
      "Epoch 27/220\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 196.3142 - mae: 11.2335 - val_loss: 220.0926 - val_mae: 12.0814\n",
      "Epoch 28/220\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 191.3008 - mae: 11.1124 - val_loss: 215.4268 - val_mae: 11.9969\n",
      "Epoch 29/220\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 186.7056 - mae: 11.0021 - val_loss: 211.0198 - val_mae: 11.8967\n",
      "Epoch 30/220\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 183.0153 - mae: 10.9184 - val_loss: 207.1673 - val_mae: 11.8122\n",
      "Epoch 31/220\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 179.3018 - mae: 10.8307 - val_loss: 203.2892 - val_mae: 11.7138\n",
      "Epoch 32/220\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 176.0699 - mae: 10.7485 - val_loss: 199.7654 - val_mae: 11.6141\n",
      "Epoch 33/220\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 173.0171 - mae: 10.6663 - val_loss: 196.4017 - val_mae: 11.5240\n",
      "Epoch 34/220\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 169.9380 - mae: 10.5835 - val_loss: 193.2414 - val_mae: 11.4385\n",
      "Epoch 35/220\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 167.2216 - mae: 10.5129 - val_loss: 190.3203 - val_mae: 11.3539\n",
      "Epoch 36/220\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 164.6830 - mae: 10.4405 - val_loss: 187.3451 - val_mae: 11.2605\n",
      "Epoch 37/220\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 162.2934 - mae: 10.3671 - val_loss: 184.7192 - val_mae: 11.1905\n",
      "Epoch 38/220\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 159.8772 - mae: 10.2982 - val_loss: 182.3214 - val_mae: 11.1260\n",
      "Epoch 39/220\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 157.9314 - mae: 10.2385 - val_loss: 179.9863 - val_mae: 11.0631\n",
      "Epoch 40/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 155.6852 - mae: 10.1727 - val_loss: 177.3305 - val_mae: 10.9786\n",
      "Epoch 41/220\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 153.8011 - mae: 10.1119 - val_loss: 175.0613 - val_mae: 10.9230\n",
      "Epoch 42/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 151.7658 - mae: 10.0475 - val_loss: 172.6124 - val_mae: 10.8460\n",
      "Epoch 43/220\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 150.2672 - mae: 9.9955 - val_loss: 170.5977 - val_mae: 10.7720\n",
      "Epoch 44/220\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 148.3674 - mae: 9.9315 - val_loss: 168.8213 - val_mae: 10.7227\n",
      "Epoch 45/220\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 146.9715 - mae: 9.8867 - val_loss: 166.6294 - val_mae: 10.6502\n",
      "Epoch 46/220\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 145.3753 - mae: 9.8333 - val_loss: 165.0982 - val_mae: 10.6040\n",
      "Epoch 47/220\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 143.7989 - mae: 9.7805 - val_loss: 163.3867 - val_mae: 10.5486\n",
      "Epoch 48/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 142.3153 - mae: 9.7175 - val_loss: 161.3651 - val_mae: 10.4604\n",
      "Epoch 49/220\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 140.4594 - mae: 9.6662 - val_loss: 158.9081 - val_mae: 10.3876\n",
      "Epoch 50/220\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 138.7319 - mae: 9.6073 - val_loss: 157.1163 - val_mae: 10.3130\n",
      "Epoch 51/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 136.9339 - mae: 9.5495 - val_loss: 155.5708 - val_mae: 10.2508\n",
      "Epoch 52/220\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 136.0050 - mae: 9.5161 - val_loss: 153.0021 - val_mae: 10.1510\n",
      "Epoch 53/220\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 134.2592 - mae: 9.4514 - val_loss: 151.4886 - val_mae: 10.0990\n",
      "Epoch 54/220\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 132.4225 - mae: 9.3850 - val_loss: 149.6838 - val_mae: 10.0394\n",
      "Epoch 55/220\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 130.9870 - mae: 9.3243 - val_loss: 147.8968 - val_mae: 9.9379\n",
      "Epoch 56/220\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 129.8079 - mae: 9.2889 - val_loss: 146.2455 - val_mae: 9.9042\n",
      "Epoch 57/220\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 128.2985 - mae: 9.2320 - val_loss: 144.4778 - val_mae: 9.8220\n",
      "Epoch 58/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 126.7084 - mae: 9.1709 - val_loss: 142.8654 - val_mae: 9.7477\n",
      "Epoch 59/220\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 125.4004 - mae: 9.1289 - val_loss: 141.5349 - val_mae: 9.6983\n",
      "Epoch 60/220\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 4ms/step - loss: 124.2911 - mae: 9.0917 - val_loss: 140.1062 - val_mae: 9.6390\n",
      "Epoch 61/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 122.9114 - mae: 9.0377 - val_loss: 138.5240 - val_mae: 9.5772\n",
      "Epoch 62/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 121.7000 - mae: 8.9906 - val_loss: 137.0662 - val_mae: 9.5074\n",
      "Epoch 63/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 120.7558 - mae: 8.9456 - val_loss: 135.8600 - val_mae: 9.4559\n",
      "Epoch 64/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 119.2217 - mae: 8.8942 - val_loss: 134.2929 - val_mae: 9.4040\n",
      "Epoch 65/220\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 118.1017 - mae: 8.8484 - val_loss: 132.8866 - val_mae: 9.3276\n",
      "Epoch 66/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 117.1734 - mae: 8.8155 - val_loss: 131.5273 - val_mae: 9.2792\n",
      "Epoch 67/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 115.5951 - mae: 8.7480 - val_loss: 129.8588 - val_mae: 9.2139\n",
      "Epoch 68/220\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 114.3955 - mae: 8.6939 - val_loss: 128.4422 - val_mae: 9.1515\n",
      "Epoch 69/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 113.2583 - mae: 8.6377 - val_loss: 127.3540 - val_mae: 9.0821\n",
      "Epoch 70/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 112.0374 - mae: 8.5896 - val_loss: 126.0987 - val_mae: 9.0255\n",
      "Epoch 71/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 110.8266 - mae: 8.5294 - val_loss: 124.5733 - val_mae: 8.9757\n",
      "Epoch 72/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 109.6553 - mae: 8.4884 - val_loss: 123.2788 - val_mae: 8.9278\n",
      "Epoch 73/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 108.5537 - mae: 8.4328 - val_loss: 121.9347 - val_mae: 8.8574\n",
      "Epoch 74/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 107.2297 - mae: 8.3788 - val_loss: 120.6831 - val_mae: 8.7987\n",
      "Epoch 75/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 105.8931 - mae: 8.3108 - val_loss: 119.2012 - val_mae: 8.7494\n",
      "Epoch 76/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 104.6839 - mae: 8.2575 - val_loss: 118.0659 - val_mae: 8.6854\n",
      "Epoch 77/220\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 103.4909 - mae: 8.2042 - val_loss: 116.6598 - val_mae: 8.6196\n",
      "Epoch 78/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 102.2600 - mae: 8.1462 - val_loss: 115.2702 - val_mae: 8.5695\n",
      "Epoch 79/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 101.0971 - mae: 8.0898 - val_loss: 113.9828 - val_mae: 8.5062\n",
      "Epoch 80/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 99.9663 - mae: 8.0364 - val_loss: 112.7927 - val_mae: 8.4473\n",
      "Epoch 81/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 99.0338 - mae: 7.9871 - val_loss: 111.5033 - val_mae: 8.4067\n",
      "Epoch 82/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 97.8895 - mae: 7.9438 - val_loss: 110.4055 - val_mae: 8.3493\n",
      "Epoch 83/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 96.6634 - mae: 7.8729 - val_loss: 108.9436 - val_mae: 8.2969\n",
      "Epoch 84/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 95.7594 - mae: 7.8317 - val_loss: 107.5736 - val_mae: 8.2572\n",
      "Epoch 85/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 94.7262 - mae: 7.7896 - val_loss: 106.8532 - val_mae: 8.2066\n",
      "Epoch 86/220\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 93.4800 - mae: 7.7170 - val_loss: 105.3740 - val_mae: 8.1554\n",
      "Epoch 87/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 92.6749 - mae: 7.6828 - val_loss: 104.3547 - val_mae: 8.1064\n",
      "Epoch 88/220\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 91.4585 - mae: 7.6265 - val_loss: 103.0009 - val_mae: 8.0616\n",
      "Epoch 89/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 90.5165 - mae: 7.5836 - val_loss: 101.6603 - val_mae: 7.9978\n",
      "Epoch 90/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 89.4258 - mae: 7.5262 - val_loss: 100.6726 - val_mae: 7.9555\n",
      "Epoch 91/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 88.4066 - mae: 7.4732 - val_loss: 99.6717 - val_mae: 7.9203\n",
      "Epoch 92/220\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 87.3710 - mae: 7.4336 - val_loss: 98.3838 - val_mae: 7.8592\n",
      "Epoch 93/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 86.4758 - mae: 7.3882 - val_loss: 97.4793 - val_mae: 7.8189\n",
      "Epoch 94/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 85.3697 - mae: 7.3238 - val_loss: 96.2012 - val_mae: 7.7625\n",
      "Epoch 95/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 84.6010 - mae: 7.2868 - val_loss: 95.0514 - val_mae: 7.7210\n",
      "Epoch 96/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 83.5397 - mae: 7.2343 - val_loss: 93.9471 - val_mae: 7.6642\n",
      "Epoch 97/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 82.6397 - mae: 7.1884 - val_loss: 93.0024 - val_mae: 7.6301\n",
      "Epoch 98/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 81.8167 - mae: 7.1455 - val_loss: 92.0470 - val_mae: 7.5882\n",
      "Epoch 99/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 80.9144 - mae: 7.0972 - val_loss: 91.2716 - val_mae: 7.5583\n",
      "Epoch 100/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 80.0643 - mae: 7.0512 - val_loss: 90.4225 - val_mae: 7.5052\n",
      "Epoch 101/220\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 79.4030 - mae: 7.0188 - val_loss: 89.3771 - val_mae: 7.4689\n",
      "Epoch 102/220\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 78.9673 - mae: 6.9944 - val_loss: 88.6216 - val_mae: 7.4418\n",
      "Epoch 103/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 77.8409 - mae: 6.9308 - val_loss: 87.2769 - val_mae: 7.3739\n",
      "Epoch 104/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 77.0814 - mae: 6.8922 - val_loss: 86.7848 - val_mae: 7.3594\n",
      "Epoch 105/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 76.1450 - mae: 6.8420 - val_loss: 86.1471 - val_mae: 7.3219\n",
      "Epoch 106/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 75.3256 - mae: 6.7967 - val_loss: 85.1212 - val_mae: 7.2884\n",
      "Epoch 107/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 74.6641 - mae: 6.7604 - val_loss: 84.3700 - val_mae: 7.2500\n",
      "Epoch 108/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 73.9026 - mae: 6.7135 - val_loss: 83.7320 - val_mae: 7.2146\n",
      "Epoch 109/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 73.2152 - mae: 6.6816 - val_loss: 82.9033 - val_mae: 7.1741\n",
      "Epoch 110/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 72.6638 - mae: 6.6485 - val_loss: 82.4607 - val_mae: 7.1505\n",
      "Epoch 111/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 71.8775 - mae: 6.6018 - val_loss: 81.6387 - val_mae: 7.1239\n",
      "Epoch 112/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 71.3260 - mae: 6.5775 - val_loss: 81.1014 - val_mae: 7.0937\n",
      "Epoch 113/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 70.8541 - mae: 6.5350 - val_loss: 80.2688 - val_mae: 7.0562\n",
      "Epoch 114/220\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 70.3485 - mae: 6.5130 - val_loss: 79.8684 - val_mae: 7.0674\n",
      "Epoch 115/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 69.4712 - mae: 6.4597 - val_loss: 79.4210 - val_mae: 7.0190\n",
      "Epoch 116/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 68.8923 - mae: 6.4237 - val_loss: 78.4879 - val_mae: 6.9874\n",
      "Epoch 117/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 68.1433 - mae: 6.3882 - val_loss: 77.9268 - val_mae: 6.9521\n",
      "Epoch 118/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 67.2900 - mae: 6.3476 - val_loss: 77.4521 - val_mae: 6.9370\n",
      "Epoch 119/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 66.5228 - mae: 6.3078 - val_loss: 76.8979 - val_mae: 6.9075\n",
      "Epoch 120/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 65.8522 - mae: 6.2801 - val_loss: 76.2066 - val_mae: 6.8579\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 121/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 65.3104 - mae: 6.2445 - val_loss: 75.7430 - val_mae: 6.8548\n",
      "Epoch 122/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 64.3600 - mae: 6.2046 - val_loss: 75.2904 - val_mae: 6.8294\n",
      "Epoch 123/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 63.9028 - mae: 6.1869 - val_loss: 74.2974 - val_mae: 6.7896\n",
      "Epoch 124/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 63.2223 - mae: 6.1401 - val_loss: 73.8807 - val_mae: 6.7751\n",
      "Epoch 125/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 62.8679 - mae: 6.1267 - val_loss: 73.4377 - val_mae: 6.7593\n",
      "Epoch 126/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 62.3905 - mae: 6.1063 - val_loss: 73.3736 - val_mae: 6.7695\n",
      "Epoch 127/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 61.8536 - mae: 6.0868 - val_loss: 72.8619 - val_mae: 6.7575\n",
      "Epoch 128/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 61.5780 - mae: 6.0578 - val_loss: 72.5562 - val_mae: 6.7490\n",
      "Epoch 129/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 60.9936 - mae: 6.0364 - val_loss: 72.1645 - val_mae: 6.7438\n",
      "Epoch 130/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 60.6859 - mae: 6.0202 - val_loss: 71.7767 - val_mae: 6.7343\n",
      "Epoch 131/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 60.1654 - mae: 6.0000 - val_loss: 71.2432 - val_mae: 6.6967\n",
      "Epoch 132/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 59.8959 - mae: 5.9926 - val_loss: 71.3519 - val_mae: 6.7264\n",
      "Epoch 133/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 59.5152 - mae: 5.9457 - val_loss: 71.0543 - val_mae: 6.7091\n",
      "Epoch 134/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 59.2423 - mae: 5.9428 - val_loss: 70.8663 - val_mae: 6.7026\n",
      "Epoch 135/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 58.6685 - mae: 5.9137 - val_loss: 70.2024 - val_mae: 6.6744\n",
      "Epoch 136/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 58.2762 - mae: 5.8961 - val_loss: 69.7235 - val_mae: 6.6597\n",
      "Epoch 137/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 58.1235 - mae: 5.8866 - val_loss: 69.7951 - val_mae: 6.6627\n",
      "Epoch 138/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 57.5672 - mae: 5.8588 - val_loss: 69.1227 - val_mae: 6.6330\n",
      "Epoch 139/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 57.3536 - mae: 5.8219 - val_loss: 68.9970 - val_mae: 6.6398\n",
      "Epoch 140/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 56.9906 - mae: 5.8228 - val_loss: 68.8564 - val_mae: 6.6242\n",
      "Epoch 141/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 56.5718 - mae: 5.7999 - val_loss: 68.5921 - val_mae: 6.6117\n",
      "Epoch 142/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 56.4499 - mae: 5.7805 - val_loss: 68.2081 - val_mae: 6.5937\n",
      "Epoch 143/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 56.1151 - mae: 5.7512 - val_loss: 68.2840 - val_mae: 6.6064\n",
      "Epoch 144/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 55.7231 - mae: 5.7299 - val_loss: 68.0564 - val_mae: 6.6070\n",
      "Epoch 145/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 55.4029 - mae: 5.7066 - val_loss: 67.8535 - val_mae: 6.5809\n",
      "Epoch 146/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 55.1905 - mae: 5.7057 - val_loss: 67.6609 - val_mae: 6.5739\n",
      "Epoch 147/220\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 54.9711 - mae: 5.6767 - val_loss: 67.3420 - val_mae: 6.5737\n",
      "Epoch 148/220\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 54.5273 - mae: 5.6615 - val_loss: 67.3984 - val_mae: 6.5539\n",
      "Epoch 149/220\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 54.4416 - mae: 5.6528 - val_loss: 66.9083 - val_mae: 6.5329\n",
      "Epoch 150/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 54.1046 - mae: 5.6495 - val_loss: 66.6688 - val_mae: 6.5281\n",
      "Epoch 151/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 53.7038 - mae: 5.6221 - val_loss: 66.5709 - val_mae: 6.5189\n",
      "Epoch 152/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 53.6578 - mae: 5.6152 - val_loss: 66.0518 - val_mae: 6.4739\n",
      "Epoch 153/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 53.3280 - mae: 5.6025 - val_loss: 65.9762 - val_mae: 6.4952\n",
      "Epoch 154/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 53.1964 - mae: 5.5831 - val_loss: 65.7169 - val_mae: 6.4681\n",
      "Epoch 155/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 52.7923 - mae: 5.5670 - val_loss: 65.7268 - val_mae: 6.4701\n",
      "Epoch 156/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 52.9291 - mae: 5.5765 - val_loss: 65.2078 - val_mae: 6.4514\n",
      "Epoch 157/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 52.2137 - mae: 5.5334 - val_loss: 65.2289 - val_mae: 6.4341\n",
      "Epoch 158/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 52.1985 - mae: 5.5303 - val_loss: 64.6294 - val_mae: 6.4090\n",
      "Epoch 159/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 51.8788 - mae: 5.5183 - val_loss: 64.4872 - val_mae: 6.3853\n",
      "Epoch 160/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 51.4620 - mae: 5.4748 - val_loss: 64.4527 - val_mae: 6.4135\n",
      "Epoch 161/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 51.4454 - mae: 5.4882 - val_loss: 63.9149 - val_mae: 6.3693\n",
      "Epoch 162/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 51.0636 - mae: 5.4673 - val_loss: 63.6318 - val_mae: 6.3466\n",
      "Epoch 163/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 50.7763 - mae: 5.4440 - val_loss: 63.4892 - val_mae: 6.3399\n",
      "Epoch 164/220\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 50.8238 - mae: 5.4432 - val_loss: 63.5197 - val_mae: 6.3469\n",
      "Epoch 165/220\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 50.6220 - mae: 5.4445 - val_loss: 62.9760 - val_mae: 6.2993\n",
      "Epoch 166/220\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 50.2951 - mae: 5.4106 - val_loss: 62.6717 - val_mae: 6.2687\n",
      "Epoch 167/220\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 50.1040 - mae: 5.3912 - val_loss: 62.6655 - val_mae: 6.2792\n",
      "Epoch 168/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 49.9171 - mae: 5.3835 - val_loss: 62.4283 - val_mae: 6.2830\n",
      "Epoch 169/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 49.7075 - mae: 5.3778 - val_loss: 62.1930 - val_mae: 6.2647\n",
      "Epoch 170/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 49.4100 - mae: 5.3464 - val_loss: 62.0185 - val_mae: 6.2340\n",
      "Epoch 171/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 49.2294 - mae: 5.3476 - val_loss: 61.8257 - val_mae: 6.2128\n",
      "Epoch 172/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 49.5243 - mae: 5.3745 - val_loss: 61.6199 - val_mae: 6.2241\n",
      "Epoch 173/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 48.7012 - mae: 5.3191 - val_loss: 61.9804 - val_mae: 6.2286\n",
      "Epoch 174/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 48.5601 - mae: 5.2987 - val_loss: 61.9513 - val_mae: 6.2244\n",
      "Epoch 175/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 48.4745 - mae: 5.2896 - val_loss: 61.4971 - val_mae: 6.1956\n",
      "Epoch 176/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 48.2724 - mae: 5.2935 - val_loss: 61.5398 - val_mae: 6.1776\n",
      "Epoch 177/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 48.1626 - mae: 5.2770 - val_loss: 61.7654 - val_mae: 6.2032\n",
      "Epoch 178/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 47.9360 - mae: 5.2600 - val_loss: 61.1126 - val_mae: 6.1730\n",
      "Epoch 179/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 47.5259 - mae: 5.2499 - val_loss: 60.8479 - val_mae: 6.1590\n",
      "Epoch 180/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 47.5593 - mae: 5.2330 - val_loss: 61.2035 - val_mae: 6.1584\n",
      "Epoch 181/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 47.2369 - mae: 5.2359 - val_loss: 60.7326 - val_mae: 6.1329\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 182/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 47.2817 - mae: 5.2262 - val_loss: 61.0732 - val_mae: 6.1706\n",
      "Epoch 183/220\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 47.1346 - mae: 5.2337 - val_loss: 60.5749 - val_mae: 6.1262\n",
      "Epoch 184/220\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 47.1953 - mae: 5.2310 - val_loss: 60.5493 - val_mae: 6.1367\n",
      "Epoch 185/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 46.7177 - mae: 5.2039 - val_loss: 60.7282 - val_mae: 6.1258\n",
      "Epoch 186/220\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 46.2989 - mae: 5.1885 - val_loss: 59.8911 - val_mae: 6.0771\n",
      "Epoch 187/220\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 46.2087 - mae: 5.1674 - val_loss: 60.1076 - val_mae: 6.0960\n",
      "Epoch 188/220\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 46.0879 - mae: 5.1721 - val_loss: 60.0881 - val_mae: 6.1100\n",
      "Epoch 189/220\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 46.2021 - mae: 5.1852 - val_loss: 59.5880 - val_mae: 6.0564\n",
      "Epoch 190/220\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 45.6315 - mae: 5.1429 - val_loss: 60.0013 - val_mae: 6.0906\n",
      "Epoch 191/220\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 45.4464 - mae: 5.1288 - val_loss: 59.4102 - val_mae: 6.0427\n",
      "Epoch 192/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 45.2865 - mae: 5.1445 - val_loss: 59.1741 - val_mae: 6.0265\n",
      "Epoch 193/220\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 45.2904 - mae: 5.1426 - val_loss: 59.2561 - val_mae: 6.0176\n",
      "Epoch 194/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 44.9912 - mae: 5.1226 - val_loss: 59.2470 - val_mae: 6.0181\n",
      "Epoch 195/220\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 44.7401 - mae: 5.0943 - val_loss: 58.9197 - val_mae: 6.0124\n",
      "Epoch 196/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 44.7422 - mae: 5.1034 - val_loss: 58.9520 - val_mae: 6.0073\n",
      "Epoch 197/220\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 44.3192 - mae: 5.0782 - val_loss: 58.8025 - val_mae: 5.9905\n",
      "Epoch 198/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 44.3607 - mae: 5.0814 - val_loss: 58.3809 - val_mae: 5.9841\n",
      "Epoch 199/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 44.1585 - mae: 5.0481 - val_loss: 58.3805 - val_mae: 5.9832\n",
      "Epoch 200/220\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 44.5551 - mae: 5.1135 - val_loss: 58.2099 - val_mae: 5.9616\n",
      "Epoch 201/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 43.9176 - mae: 5.0578 - val_loss: 58.1629 - val_mae: 5.9638\n",
      "Epoch 202/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 43.8197 - mae: 5.0343 - val_loss: 58.5203 - val_mae: 5.9763\n",
      "Epoch 203/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 43.7334 - mae: 5.0447 - val_loss: 58.5729 - val_mae: 5.9777\n",
      "Epoch 204/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 43.6034 - mae: 5.0432 - val_loss: 57.4647 - val_mae: 5.9242\n",
      "Epoch 205/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 43.4442 - mae: 5.0149 - val_loss: 57.4549 - val_mae: 5.9184\n",
      "Epoch 206/220\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 43.0965 - mae: 4.9925 - val_loss: 57.4777 - val_mae: 5.9117\n",
      "Epoch 207/220\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 43.0820 - mae: 5.0224 - val_loss: 57.3836 - val_mae: 5.9031\n",
      "Epoch 208/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 42.8574 - mae: 4.9843 - val_loss: 57.1488 - val_mae: 5.8908\n",
      "Epoch 209/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 42.8272 - mae: 4.9933 - val_loss: 57.2008 - val_mae: 5.8825\n",
      "Epoch 210/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 43.2569 - mae: 5.0355 - val_loss: 57.3382 - val_mae: 5.9216\n",
      "Epoch 211/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 42.5754 - mae: 4.9755 - val_loss: 56.8308 - val_mae: 5.8774\n",
      "Epoch 212/220\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 42.3711 - mae: 4.9562 - val_loss: 56.3825 - val_mae: 5.8578\n",
      "Epoch 213/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 42.2192 - mae: 4.9396 - val_loss: 56.6722 - val_mae: 5.8757\n",
      "Epoch 214/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 42.3209 - mae: 4.9703 - val_loss: 56.2080 - val_mae: 5.8312\n",
      "Epoch 215/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 41.6631 - mae: 4.9068 - val_loss: 55.9439 - val_mae: 5.8225\n",
      "Epoch 216/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 41.6720 - mae: 4.9272 - val_loss: 55.8559 - val_mae: 5.8092\n",
      "Epoch 217/220\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 41.6245 - mae: 4.8940 - val_loss: 55.7664 - val_mae: 5.8205\n",
      "Epoch 218/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 41.7761 - mae: 4.9199 - val_loss: 55.5706 - val_mae: 5.8023\n",
      "Epoch 219/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 41.1870 - mae: 4.8835 - val_loss: 55.0661 - val_mae: 5.7720\n",
      "Epoch 220/220\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 41.1779 - mae: 4.8748 - val_loss: 55.0529 - val_mae: 5.7678\n",
      "processing fold # 1\n",
      "Epoch 1/220\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 1654.5775 - mae: 36.8414 - val_loss: 1436.5540 - val_mae: 34.1330\n",
      "Epoch 2/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 1606.3093 - mae: 36.2073 - val_loss: 1393.4667 - val_mae: 33.5213\n",
      "Epoch 3/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 1560.9061 - mae: 35.5830 - val_loss: 1349.0759 - val_mae: 32.8775\n",
      "Epoch 4/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 1513.8353 - mae: 34.9154 - val_loss: 1301.9545 - val_mae: 32.1809\n",
      "Epoch 5/220\n",
      "34/34 [==============================] - 0s 13ms/step - loss: 1461.9000 - mae: 34.1778 - val_loss: 1248.6973 - val_mae: 31.3866\n",
      "Epoch 6/220\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1401.3048 - mae: 33.3208 - val_loss: 1189.4211 - val_mae: 30.4870\n",
      "Epoch 7/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 1332.5490 - mae: 32.3361 - val_loss: 1121.0991 - val_mae: 29.4396\n",
      "Epoch 8/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 1252.6713 - mae: 31.1777 - val_loss: 1044.9960 - val_mae: 28.2388\n",
      "Epoch 9/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 1161.7473 - mae: 29.8263 - val_loss: 960.0169 - val_mae: 26.8496\n",
      "Epoch 10/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 1060.6230 - mae: 28.3166 - val_loss: 868.9429 - val_mae: 25.2868\n",
      "Epoch 11/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 953.0620 - mae: 26.5606 - val_loss: 773.1608 - val_mae: 23.5464\n",
      "Epoch 12/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 839.7303 - mae: 24.6670 - val_loss: 678.9911 - val_mae: 21.7308\n",
      "Epoch 13/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 727.5272 - mae: 22.6422 - val_loss: 586.3427 - val_mae: 19.9174\n",
      "Epoch 14/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 620.0411 - mae: 20.6087 - val_loss: 501.8615 - val_mae: 18.1657\n",
      "Epoch 15/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 521.8302 - mae: 18.6799 - val_loss: 426.3557 - val_mae: 16.4968\n",
      "Epoch 16/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 436.5679 - mae: 16.8456 - val_loss: 362.9307 - val_mae: 15.2105\n",
      "Epoch 17/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 366.1007 - mae: 15.2529 - val_loss: 311.8748 - val_mae: 14.1968\n",
      "Epoch 18/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 310.2353 - mae: 13.9484 - val_loss: 274.1949 - val_mae: 13.3088\n",
      "Epoch 19/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 269.4816 - mae: 12.9747 - val_loss: 246.4739 - val_mae: 12.6091\n",
      "Epoch 20/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 239.8706 - mae: 12.2094 - val_loss: 226.4710 - val_mae: 12.1068\n",
      "Epoch 21/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 219.2636 - mae: 11.6760 - val_loss: 213.2039 - val_mae: 11.7514\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 205.2434 - mae: 11.3037 - val_loss: 204.1126 - val_mae: 11.4724\n",
      "Epoch 23/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 195.5715 - mae: 11.0325 - val_loss: 197.5567 - val_mae: 11.2968\n",
      "Epoch 24/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 188.3792 - mae: 10.8368 - val_loss: 192.4724 - val_mae: 11.1585\n",
      "Epoch 25/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 183.1509 - mae: 10.6987 - val_loss: 188.7699 - val_mae: 11.0556\n",
      "Epoch 26/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 178.6840 - mae: 10.5801 - val_loss: 185.1408 - val_mae: 10.9583\n",
      "Epoch 27/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 175.1257 - mae: 10.5009 - val_loss: 182.1335 - val_mae: 10.8840\n",
      "Epoch 28/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 171.8888 - mae: 10.4217 - val_loss: 179.0027 - val_mae: 10.8063\n",
      "Epoch 29/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 168.9016 - mae: 10.3421 - val_loss: 176.6299 - val_mae: 10.7417\n",
      "Epoch 30/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 165.9941 - mae: 10.2820 - val_loss: 173.8236 - val_mae: 10.6761\n",
      "Epoch 31/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 163.7349 - mae: 10.2237 - val_loss: 171.4500 - val_mae: 10.6241\n",
      "Epoch 32/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 161.3098 - mae: 10.1580 - val_loss: 169.3704 - val_mae: 10.5645\n",
      "Epoch 33/220\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 159.0926 - mae: 10.0947 - val_loss: 166.6302 - val_mae: 10.5005\n",
      "Epoch 34/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 157.0203 - mae: 10.0399 - val_loss: 164.3637 - val_mae: 10.4367\n",
      "Epoch 35/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 155.2322 - mae: 9.9789 - val_loss: 162.9550 - val_mae: 10.3771\n",
      "Epoch 36/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 153.3104 - mae: 9.9269 - val_loss: 160.4484 - val_mae: 10.3282\n",
      "Epoch 37/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 151.5991 - mae: 9.8786 - val_loss: 158.7307 - val_mae: 10.2834\n",
      "Epoch 38/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 149.8885 - mae: 9.8241 - val_loss: 156.8068 - val_mae: 10.2292\n",
      "Epoch 39/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 148.2913 - mae: 9.7761 - val_loss: 155.1679 - val_mae: 10.1782\n",
      "Epoch 40/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 146.7557 - mae: 9.7289 - val_loss: 153.4703 - val_mae: 10.1236\n",
      "Epoch 41/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 145.7361 - mae: 9.6826 - val_loss: 152.0453 - val_mae: 10.0681\n",
      "Epoch 42/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 143.7628 - mae: 9.6331 - val_loss: 150.3218 - val_mae: 10.0308\n",
      "Epoch 43/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 142.3433 - mae: 9.5968 - val_loss: 148.3784 - val_mae: 9.9885\n",
      "Epoch 44/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 141.0588 - mae: 9.5510 - val_loss: 146.9922 - val_mae: 9.9404\n",
      "Epoch 45/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 139.6422 - mae: 9.5013 - val_loss: 145.6153 - val_mae: 9.8918\n",
      "Epoch 46/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 138.2653 - mae: 9.4544 - val_loss: 144.5627 - val_mae: 9.8519\n",
      "Epoch 47/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 137.0165 - mae: 9.4048 - val_loss: 143.3324 - val_mae: 9.8023\n",
      "Epoch 48/220\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 135.7160 - mae: 9.3640 - val_loss: 141.8958 - val_mae: 9.7588\n",
      "Epoch 49/220\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 134.5549 - mae: 9.3104 - val_loss: 140.7700 - val_mae: 9.7141\n",
      "Epoch 50/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 133.1638 - mae: 9.2647 - val_loss: 139.4177 - val_mae: 9.6713\n",
      "Epoch 51/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 131.7836 - mae: 9.2173 - val_loss: 137.9551 - val_mae: 9.6244\n",
      "Epoch 52/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 130.4227 - mae: 9.1709 - val_loss: 136.8040 - val_mae: 9.5810\n",
      "Epoch 53/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 128.9789 - mae: 9.1215 - val_loss: 135.2436 - val_mae: 9.5275\n",
      "Epoch 54/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 127.6348 - mae: 9.0668 - val_loss: 133.6531 - val_mae: 9.4722\n",
      "Epoch 55/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 126.1536 - mae: 9.0154 - val_loss: 131.9028 - val_mae: 9.4107\n",
      "Epoch 56/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 124.3873 - mae: 8.9523 - val_loss: 130.8875 - val_mae: 9.3677\n",
      "Epoch 57/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 122.8797 - mae: 8.8949 - val_loss: 129.2485 - val_mae: 9.3049\n",
      "Epoch 58/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 121.2987 - mae: 8.8256 - val_loss: 127.7002 - val_mae: 9.2421\n",
      "Epoch 59/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 119.4557 - mae: 8.7558 - val_loss: 125.9593 - val_mae: 9.1775\n",
      "Epoch 60/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 117.7185 - mae: 8.6779 - val_loss: 124.5543 - val_mae: 9.1129\n",
      "Epoch 61/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 115.9961 - mae: 8.6111 - val_loss: 122.7524 - val_mae: 9.0451\n",
      "Epoch 62/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 114.0727 - mae: 8.5350 - val_loss: 120.9852 - val_mae: 8.9771\n",
      "Epoch 63/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 112.3465 - mae: 8.4556 - val_loss: 119.5934 - val_mae: 8.9138\n",
      "Epoch 64/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 110.4016 - mae: 8.3823 - val_loss: 117.3711 - val_mae: 8.8389\n",
      "Epoch 65/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 108.6745 - mae: 8.3117 - val_loss: 116.2759 - val_mae: 8.7867\n",
      "Epoch 66/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 106.8837 - mae: 8.2352 - val_loss: 114.1027 - val_mae: 8.7049\n",
      "Epoch 67/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 104.9347 - mae: 8.1526 - val_loss: 112.4121 - val_mae: 8.6280\n",
      "Epoch 68/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 103.3258 - mae: 8.0729 - val_loss: 111.0628 - val_mae: 8.5583\n",
      "Epoch 69/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 101.3215 - mae: 8.0013 - val_loss: 109.1961 - val_mae: 8.4900\n",
      "Epoch 70/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 99.3929 - mae: 7.9115 - val_loss: 107.1582 - val_mae: 8.4067\n",
      "Epoch 71/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 97.8064 - mae: 7.8480 - val_loss: 105.7422 - val_mae: 8.3392\n",
      "Epoch 72/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 95.9181 - mae: 7.7648 - val_loss: 104.2934 - val_mae: 8.2709\n",
      "Epoch 73/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 94.4150 - mae: 7.6989 - val_loss: 102.1551 - val_mae: 8.1759\n",
      "Epoch 74/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 92.8487 - mae: 7.6309 - val_loss: 100.8369 - val_mae: 8.1089\n",
      "Epoch 75/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 91.4701 - mae: 7.5672 - val_loss: 99.7390 - val_mae: 8.0606\n",
      "Epoch 76/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 90.0823 - mae: 7.4935 - val_loss: 97.8886 - val_mae: 7.9723\n",
      "Epoch 77/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 88.3092 - mae: 7.4200 - val_loss: 96.5016 - val_mae: 7.8950\n",
      "Epoch 78/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 86.9420 - mae: 7.3576 - val_loss: 95.3669 - val_mae: 7.8359\n",
      "Epoch 79/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 85.8344 - mae: 7.3088 - val_loss: 93.5304 - val_mae: 7.7468\n",
      "Epoch 80/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 84.4479 - mae: 7.2396 - val_loss: 92.3193 - val_mae: 7.6921\n",
      "Epoch 81/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 82.9273 - mae: 7.1698 - val_loss: 91.1157 - val_mae: 7.6175\n",
      "Epoch 82/220\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 3ms/step - loss: 81.7990 - mae: 7.1088 - val_loss: 89.6240 - val_mae: 7.5426\n",
      "Epoch 83/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 80.1406 - mae: 7.0182 - val_loss: 87.6266 - val_mae: 7.4458\n",
      "Epoch 84/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 78.7384 - mae: 6.9572 - val_loss: 85.9658 - val_mae: 7.3303\n",
      "Epoch 85/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 77.0687 - mae: 6.8609 - val_loss: 84.3228 - val_mae: 7.2448\n",
      "Epoch 86/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 75.7913 - mae: 6.7857 - val_loss: 83.0905 - val_mae: 7.1822\n",
      "Epoch 87/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 74.2539 - mae: 6.7114 - val_loss: 81.7832 - val_mae: 7.0948\n",
      "Epoch 88/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 73.1031 - mae: 6.6371 - val_loss: 80.1346 - val_mae: 7.0102\n",
      "Epoch 89/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 71.9925 - mae: 6.5840 - val_loss: 79.3741 - val_mae: 6.9616\n",
      "Epoch 90/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 70.4525 - mae: 6.4969 - val_loss: 77.9449 - val_mae: 6.8770\n",
      "Epoch 91/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 69.2564 - mae: 6.4295 - val_loss: 76.7572 - val_mae: 6.8117\n",
      "Epoch 92/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 68.0303 - mae: 6.3582 - val_loss: 75.7205 - val_mae: 6.7344\n",
      "Epoch 93/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 66.8687 - mae: 6.3055 - val_loss: 74.9148 - val_mae: 6.6840\n",
      "Epoch 94/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 65.8258 - mae: 6.2546 - val_loss: 73.8451 - val_mae: 6.6148\n",
      "Epoch 95/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 64.6819 - mae: 6.1781 - val_loss: 72.6419 - val_mae: 6.5550\n",
      "Epoch 96/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 63.8387 - mae: 6.1286 - val_loss: 71.0576 - val_mae: 6.4843\n",
      "Epoch 97/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 62.6180 - mae: 6.0740 - val_loss: 70.8183 - val_mae: 6.4341\n",
      "Epoch 98/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 61.5674 - mae: 6.0238 - val_loss: 69.8134 - val_mae: 6.3818\n",
      "Epoch 99/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 60.7365 - mae: 5.9820 - val_loss: 68.4784 - val_mae: 6.3212\n",
      "Epoch 100/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 59.7313 - mae: 5.9440 - val_loss: 68.0030 - val_mae: 6.2693\n",
      "Epoch 101/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 58.7752 - mae: 5.8725 - val_loss: 67.1204 - val_mae: 6.2172\n",
      "Epoch 102/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 57.7382 - mae: 5.8226 - val_loss: 65.9316 - val_mae: 6.1412\n",
      "Epoch 103/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 56.8116 - mae: 5.7716 - val_loss: 65.2438 - val_mae: 6.0842\n",
      "Epoch 104/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 56.1733 - mae: 5.7352 - val_loss: 64.3116 - val_mae: 6.0284\n",
      "Epoch 105/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 55.3940 - mae: 5.6888 - val_loss: 63.6512 - val_mae: 5.9925\n",
      "Epoch 106/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 54.6430 - mae: 5.6554 - val_loss: 63.1715 - val_mae: 5.9583\n",
      "Epoch 107/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 53.9851 - mae: 5.6306 - val_loss: 62.2378 - val_mae: 5.9010\n",
      "Epoch 108/220\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 53.4054 - mae: 5.5936 - val_loss: 61.8169 - val_mae: 5.8579\n",
      "Epoch 109/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 52.6480 - mae: 5.5436 - val_loss: 60.7517 - val_mae: 5.8138\n",
      "Epoch 110/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 51.9337 - mae: 5.5170 - val_loss: 60.4041 - val_mae: 5.7731\n",
      "Epoch 111/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 51.5091 - mae: 5.5024 - val_loss: 59.8251 - val_mae: 5.7389\n",
      "Epoch 112/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 50.6211 - mae: 5.4299 - val_loss: 59.2324 - val_mae: 5.6924\n",
      "Epoch 113/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 50.2499 - mae: 5.4088 - val_loss: 58.4483 - val_mae: 5.6510\n",
      "Epoch 114/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 49.4730 - mae: 5.3737 - val_loss: 58.3330 - val_mae: 5.6307\n",
      "Epoch 115/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 49.1127 - mae: 5.3516 - val_loss: 58.0322 - val_mae: 5.6040\n",
      "Epoch 116/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 48.4489 - mae: 5.3083 - val_loss: 57.0732 - val_mae: 5.5597\n",
      "Epoch 117/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 48.0558 - mae: 5.2820 - val_loss: 56.7737 - val_mae: 5.5317\n",
      "Epoch 118/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 47.5742 - mae: 5.2708 - val_loss: 56.3949 - val_mae: 5.5126\n",
      "Epoch 119/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 47.0824 - mae: 5.2202 - val_loss: 55.9779 - val_mae: 5.4900\n",
      "Epoch 120/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 46.6737 - mae: 5.2223 - val_loss: 55.2962 - val_mae: 5.4478\n",
      "Epoch 121/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 46.2255 - mae: 5.1774 - val_loss: 55.0029 - val_mae: 5.4246\n",
      "Epoch 122/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 45.8273 - mae: 5.1433 - val_loss: 54.9013 - val_mae: 5.4185\n",
      "Epoch 123/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 45.4843 - mae: 5.1232 - val_loss: 54.3799 - val_mae: 5.3766\n",
      "Epoch 124/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 45.0383 - mae: 5.0940 - val_loss: 53.8098 - val_mae: 5.3499\n",
      "Epoch 125/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 44.7263 - mae: 5.0800 - val_loss: 53.7634 - val_mae: 5.3477\n",
      "Epoch 126/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 44.5614 - mae: 5.0437 - val_loss: 52.9203 - val_mae: 5.2933\n",
      "Epoch 127/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 44.2185 - mae: 5.0269 - val_loss: 53.4005 - val_mae: 5.3141\n",
      "Epoch 128/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 43.5769 - mae: 5.0124 - val_loss: 52.6252 - val_mae: 5.2864\n",
      "Epoch 129/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 43.5689 - mae: 4.9957 - val_loss: 52.5457 - val_mae: 5.2682\n",
      "Epoch 130/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 43.1223 - mae: 4.9665 - val_loss: 52.2060 - val_mae: 5.2449\n",
      "Epoch 131/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 42.6624 - mae: 4.9303 - val_loss: 51.5995 - val_mae: 5.2183\n",
      "Epoch 132/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 42.4969 - mae: 4.9277 - val_loss: 51.4356 - val_mae: 5.2146\n",
      "Epoch 133/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 42.3139 - mae: 4.9090 - val_loss: 51.2824 - val_mae: 5.1900\n",
      "Epoch 134/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 42.0712 - mae: 4.9031 - val_loss: 50.6737 - val_mae: 5.1716\n",
      "Epoch 135/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 41.6535 - mae: 4.8808 - val_loss: 50.6265 - val_mae: 5.1715\n",
      "Epoch 136/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 41.6059 - mae: 4.8555 - val_loss: 50.0749 - val_mae: 5.1427\n",
      "Epoch 137/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 41.1116 - mae: 4.8306 - val_loss: 50.6000 - val_mae: 5.1550\n",
      "Epoch 138/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 40.9407 - mae: 4.8191 - val_loss: 50.1617 - val_mae: 5.1571\n",
      "Epoch 139/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 40.7395 - mae: 4.8177 - val_loss: 49.6841 - val_mae: 5.1179\n",
      "Epoch 140/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 40.6774 - mae: 4.8057 - val_loss: 49.7405 - val_mae: 5.1343\n",
      "Epoch 141/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 40.5751 - mae: 4.7871 - val_loss: 49.8206 - val_mae: 5.1083\n",
      "Epoch 142/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 40.0832 - mae: 4.7787 - val_loss: 49.0446 - val_mae: 5.1110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 143/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 40.0286 - mae: 4.7428 - val_loss: 48.9810 - val_mae: 5.0840\n",
      "Epoch 144/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 40.0104 - mae: 4.7673 - val_loss: 48.9664 - val_mae: 5.0895\n",
      "Epoch 145/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 39.6228 - mae: 4.7410 - val_loss: 48.4654 - val_mae: 5.0714\n",
      "Epoch 146/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 39.2508 - mae: 4.7274 - val_loss: 48.2531 - val_mae: 5.0705\n",
      "Epoch 147/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 39.2436 - mae: 4.7208 - val_loss: 48.3375 - val_mae: 5.0647\n",
      "Epoch 148/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 39.0437 - mae: 4.7156 - val_loss: 48.1836 - val_mae: 5.0558\n",
      "Epoch 149/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 38.8555 - mae: 4.7003 - val_loss: 47.7436 - val_mae: 5.0623\n",
      "Epoch 150/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 38.7308 - mae: 4.6933 - val_loss: 47.6827 - val_mae: 5.0483\n",
      "Epoch 151/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 38.4797 - mae: 4.6813 - val_loss: 47.9162 - val_mae: 5.0593\n",
      "Epoch 152/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 38.4680 - mae: 4.6749 - val_loss: 47.5818 - val_mae: 5.0502\n",
      "Epoch 153/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 38.1389 - mae: 4.6663 - val_loss: 47.5156 - val_mae: 5.0463\n",
      "Epoch 154/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 37.9614 - mae: 4.6572 - val_loss: 47.2556 - val_mae: 5.0418\n",
      "Epoch 155/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 38.3279 - mae: 4.6746 - val_loss: 47.1435 - val_mae: 5.0403\n",
      "Epoch 156/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 38.2119 - mae: 4.6573 - val_loss: 47.8035 - val_mae: 5.0479\n",
      "Epoch 157/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 37.8657 - mae: 4.6481 - val_loss: 46.9360 - val_mae: 5.0271\n",
      "Epoch 158/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 37.6061 - mae: 4.6257 - val_loss: 46.8375 - val_mae: 5.0217\n",
      "Epoch 159/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 37.3797 - mae: 4.6098 - val_loss: 46.5966 - val_mae: 5.0237\n",
      "Epoch 160/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 37.2325 - mae: 4.6028 - val_loss: 46.9699 - val_mae: 5.0360\n",
      "Epoch 161/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 37.0997 - mae: 4.6020 - val_loss: 46.7949 - val_mae: 5.0159\n",
      "Epoch 162/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 36.9808 - mae: 4.5915 - val_loss: 46.3104 - val_mae: 5.0042\n",
      "Epoch 163/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 37.1108 - mae: 4.5986 - val_loss: 46.8122 - val_mae: 5.0180\n",
      "Epoch 164/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 36.7082 - mae: 4.5812 - val_loss: 46.4171 - val_mae: 5.0103\n",
      "Epoch 165/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 36.4721 - mae: 4.5645 - val_loss: 46.0326 - val_mae: 4.9968\n",
      "Epoch 166/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 36.5094 - mae: 4.5823 - val_loss: 46.1300 - val_mae: 5.0095\n",
      "Epoch 167/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 36.3829 - mae: 4.5438 - val_loss: 46.1345 - val_mae: 4.9975\n",
      "Epoch 168/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 36.4522 - mae: 4.5658 - val_loss: 46.2795 - val_mae: 5.0117\n",
      "Epoch 169/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 36.2841 - mae: 4.5648 - val_loss: 45.8588 - val_mae: 5.0032\n",
      "Epoch 170/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 35.9574 - mae: 4.5210 - val_loss: 45.7892 - val_mae: 5.0008\n",
      "Epoch 171/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 35.9025 - mae: 4.5230 - val_loss: 45.7280 - val_mae: 4.9948\n",
      "Epoch 172/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 35.9548 - mae: 4.5247 - val_loss: 46.2053 - val_mae: 5.0091\n",
      "Epoch 173/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 35.5528 - mae: 4.4937 - val_loss: 45.5291 - val_mae: 4.9921\n",
      "Epoch 174/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 35.5764 - mae: 4.5225 - val_loss: 45.5347 - val_mae: 4.9929\n",
      "Epoch 175/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 35.6390 - mae: 4.4894 - val_loss: 45.9654 - val_mae: 4.9953\n",
      "Epoch 176/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 35.4538 - mae: 4.4871 - val_loss: 45.8307 - val_mae: 4.9918\n",
      "Epoch 177/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 35.5467 - mae: 4.5082 - val_loss: 46.1862 - val_mae: 4.9937\n",
      "Epoch 178/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 35.0422 - mae: 4.4963 - val_loss: 45.1529 - val_mae: 4.9891\n",
      "Epoch 179/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 35.1018 - mae: 4.4586 - val_loss: 45.9278 - val_mae: 4.9897\n",
      "Epoch 180/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 35.0018 - mae: 4.4784 - val_loss: 44.9151 - val_mae: 4.9888\n",
      "Epoch 181/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 34.8874 - mae: 4.4431 - val_loss: 45.3511 - val_mae: 4.9902\n",
      "Epoch 182/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 34.7371 - mae: 4.4584 - val_loss: 45.1734 - val_mae: 4.9870\n",
      "Epoch 183/220\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 34.7126 - mae: 4.4451 - val_loss: 45.2387 - val_mae: 4.9705\n",
      "Epoch 184/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 34.7793 - mae: 4.4547 - val_loss: 44.6996 - val_mae: 4.9792\n",
      "Epoch 185/220\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 34.7831 - mae: 4.4530 - val_loss: 44.8181 - val_mae: 4.9679\n",
      "Epoch 186/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 34.6267 - mae: 4.4482 - val_loss: 45.2165 - val_mae: 4.9783\n",
      "Epoch 187/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 34.4845 - mae: 4.4408 - val_loss: 44.3388 - val_mae: 4.9600\n",
      "Epoch 188/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 34.3421 - mae: 4.4013 - val_loss: 44.6113 - val_mae: 4.9598\n",
      "Epoch 189/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 34.3029 - mae: 4.4001 - val_loss: 44.6953 - val_mae: 4.9600\n",
      "Epoch 190/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 34.4298 - mae: 4.4375 - val_loss: 44.6161 - val_mae: 4.9630\n",
      "Epoch 191/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 34.1107 - mae: 4.3965 - val_loss: 44.5404 - val_mae: 4.9510\n",
      "Epoch 192/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 34.2062 - mae: 4.4342 - val_loss: 44.3668 - val_mae: 4.9545\n",
      "Epoch 193/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 33.8923 - mae: 4.3796 - val_loss: 44.4035 - val_mae: 4.9502\n",
      "Epoch 194/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 34.0322 - mae: 4.3964 - val_loss: 44.4239 - val_mae: 4.9457\n",
      "Epoch 195/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 33.8608 - mae: 4.3860 - val_loss: 44.5522 - val_mae: 4.9738\n",
      "Epoch 196/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 33.8546 - mae: 4.3992 - val_loss: 44.6449 - val_mae: 4.9449\n",
      "Epoch 197/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 33.7894 - mae: 4.3758 - val_loss: 44.1986 - val_mae: 4.9500\n",
      "Epoch 198/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 33.8446 - mae: 4.3933 - val_loss: 44.5818 - val_mae: 4.9657\n",
      "Epoch 199/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 33.5855 - mae: 4.3536 - val_loss: 44.4213 - val_mae: 4.9476\n",
      "Epoch 200/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 33.6665 - mae: 4.3632 - val_loss: 44.5633 - val_mae: 4.9434\n",
      "Epoch 201/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 33.5763 - mae: 4.3646 - val_loss: 43.5201 - val_mae: 4.9136\n",
      "Epoch 202/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 33.4156 - mae: 4.3726 - val_loss: 44.0981 - val_mae: 4.9604\n",
      "Epoch 203/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 33.4884 - mae: 4.3608 - val_loss: 43.5009 - val_mae: 4.9328\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 204/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 33.2403 - mae: 4.3501 - val_loss: 43.8458 - val_mae: 4.9384\n",
      "Epoch 205/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 33.1324 - mae: 4.3212 - val_loss: 43.7917 - val_mae: 4.9385\n",
      "Epoch 206/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 33.1259 - mae: 4.3329 - val_loss: 43.8689 - val_mae: 4.9500\n",
      "Epoch 207/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 33.1327 - mae: 4.3465 - val_loss: 43.5715 - val_mae: 4.9327\n",
      "Epoch 208/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 33.0978 - mae: 4.3270 - val_loss: 43.4318 - val_mae: 4.9301\n",
      "Epoch 209/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 32.9278 - mae: 4.3163 - val_loss: 43.9134 - val_mae: 4.9389\n",
      "Epoch 210/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 33.0405 - mae: 4.3345 - val_loss: 43.3653 - val_mae: 4.9287\n",
      "Epoch 211/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 32.8999 - mae: 4.2856 - val_loss: 43.8843 - val_mae: 4.9441\n",
      "Epoch 212/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 32.9986 - mae: 4.3497 - val_loss: 43.3696 - val_mae: 4.9392\n",
      "Epoch 213/220\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 32.6639 - mae: 4.3033 - val_loss: 43.6041 - val_mae: 4.9342\n",
      "Epoch 214/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 32.8703 - mae: 4.3293 - val_loss: 43.5920 - val_mae: 4.9371\n",
      "Epoch 215/220\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 32.6328 - mae: 4.2838 - val_loss: 43.2275 - val_mae: 4.9274\n",
      "Epoch 216/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 32.6008 - mae: 4.3058 - val_loss: 43.4889 - val_mae: 4.9265\n",
      "Epoch 217/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 32.6006 - mae: 4.2828 - val_loss: 43.2972 - val_mae: 4.9221\n",
      "Epoch 218/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 32.5083 - mae: 4.2837 - val_loss: 43.7680 - val_mae: 4.9318\n",
      "Epoch 219/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 32.4086 - mae: 4.2812 - val_loss: 43.7330 - val_mae: 4.9373\n",
      "Epoch 220/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 32.3911 - mae: 4.2722 - val_loss: 43.3326 - val_mae: 4.9263\n",
      "processing fold # 2\n",
      "Epoch 1/220\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 1532.9575 - mae: 35.3509 - val_loss: 1675.8865 - val_mae: 37.2254\n",
      "Epoch 2/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 1517.1113 - mae: 35.1701 - val_loss: 1656.4181 - val_mae: 37.0155\n",
      "Epoch 3/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 1496.5848 - mae: 34.9265 - val_loss: 1629.6871 - val_mae: 36.7105\n",
      "Epoch 4/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 1466.8986 - mae: 34.5528 - val_loss: 1590.4391 - val_mae: 36.2376\n",
      "Epoch 5/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 1420.6294 - mae: 33.9521 - val_loss: 1532.4951 - val_mae: 35.5246\n",
      "Epoch 6/220\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1355.4395 - mae: 33.0837 - val_loss: 1450.2941 - val_mae: 34.4919\n",
      "Epoch 7/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 1270.6410 - mae: 31.9399 - val_loss: 1350.2632 - val_mae: 33.1772\n",
      "Epoch 8/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 1167.7092 - mae: 30.4452 - val_loss: 1227.3655 - val_mae: 31.4864\n",
      "Epoch 9/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 1045.9225 - mae: 28.5846 - val_loss: 1087.3595 - val_mae: 29.4181\n",
      "Epoch 10/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 910.2699 - mae: 26.3554 - val_loss: 938.7427 - val_mae: 26.9995\n",
      "Epoch 11/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 770.0081 - mae: 23.8728 - val_loss: 787.7388 - val_mae: 24.2734\n",
      "Epoch 12/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 634.9379 - mae: 21.1666 - val_loss: 642.2256 - val_mae: 21.3823\n",
      "Epoch 13/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 514.5884 - mae: 18.5797 - val_loss: 515.9797 - val_mae: 18.5728\n",
      "Epoch 14/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 414.9033 - mae: 16.4874 - val_loss: 420.6893 - val_mae: 16.3529\n",
      "Epoch 15/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 342.4187 - mae: 14.9388 - val_loss: 346.8502 - val_mae: 14.6935\n",
      "Epoch 16/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 290.8997 - mae: 13.8143 - val_loss: 296.7890 - val_mae: 13.5520\n",
      "Epoch 17/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 257.3441 - mae: 12.9661 - val_loss: 261.0916 - val_mae: 12.7969\n",
      "Epoch 18/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 234.6181 - mae: 12.3203 - val_loss: 238.7865 - val_mae: 12.2848\n",
      "Epoch 19/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 220.0865 - mae: 11.9029 - val_loss: 221.9904 - val_mae: 11.8551\n",
      "Epoch 20/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 208.7353 - mae: 11.5617 - val_loss: 212.1955 - val_mae: 11.5988\n",
      "Epoch 21/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 201.0171 - mae: 11.3344 - val_loss: 204.0629 - val_mae: 11.3763\n",
      "Epoch 22/220\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 194.8412 - mae: 11.1472 - val_loss: 197.3544 - val_mae: 11.1917\n",
      "Epoch 23/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 189.3593 - mae: 10.9962 - val_loss: 192.5989 - val_mae: 11.0677\n",
      "Epoch 24/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 185.0219 - mae: 10.8717 - val_loss: 187.9663 - val_mae: 10.9544\n",
      "Epoch 25/220\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 181.0742 - mae: 10.7508 - val_loss: 183.9094 - val_mae: 10.8232\n",
      "Epoch 26/220\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 177.5734 - mae: 10.6624 - val_loss: 180.7906 - val_mae: 10.7566\n",
      "Epoch 27/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 174.3508 - mae: 10.5636 - val_loss: 177.3690 - val_mae: 10.6559\n",
      "Epoch 28/220\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 171.1617 - mae: 10.4721 - val_loss: 174.0424 - val_mae: 10.5636\n",
      "Epoch 29/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 168.4477 - mae: 10.3903 - val_loss: 171.5628 - val_mae: 10.5021\n",
      "Epoch 30/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 165.6297 - mae: 10.3183 - val_loss: 169.0811 - val_mae: 10.4337\n",
      "Epoch 31/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 163.1680 - mae: 10.2321 - val_loss: 165.9902 - val_mae: 10.3465\n",
      "Epoch 32/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 160.6350 - mae: 10.1865 - val_loss: 165.0851 - val_mae: 10.3362\n",
      "Epoch 33/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 158.0249 - mae: 10.1051 - val_loss: 161.5724 - val_mae: 10.2262\n",
      "Epoch 34/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 155.5834 - mae: 10.0162 - val_loss: 158.9496 - val_mae: 10.1498\n",
      "Epoch 35/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 153.4277 - mae: 9.9453 - val_loss: 157.1243 - val_mae: 10.0911\n",
      "Epoch 36/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 151.1405 - mae: 9.8899 - val_loss: 155.2093 - val_mae: 10.0441\n",
      "Epoch 37/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 148.8788 - mae: 9.8100 - val_loss: 152.4921 - val_mae: 9.9574\n",
      "Epoch 38/220\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 146.8829 - mae: 9.7483 - val_loss: 150.6220 - val_mae: 9.9004\n",
      "Epoch 39/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 144.9396 - mae: 9.6932 - val_loss: 148.6821 - val_mae: 9.8386\n",
      "Epoch 40/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 143.2178 - mae: 9.6322 - val_loss: 146.2812 - val_mae: 9.7681\n",
      "Epoch 41/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 140.8842 - mae: 9.5738 - val_loss: 144.8846 - val_mae: 9.7085\n",
      "Epoch 42/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 138.5288 - mae: 9.4872 - val_loss: 142.3372 - val_mae: 9.6246\n",
      "Epoch 43/220\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 3ms/step - loss: 136.6684 - mae: 9.4185 - val_loss: 140.1495 - val_mae: 9.5339\n",
      "Epoch 44/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 134.5296 - mae: 9.3453 - val_loss: 138.2326 - val_mae: 9.4751\n",
      "Epoch 45/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 132.5835 - mae: 9.2751 - val_loss: 136.6801 - val_mae: 9.4118\n",
      "Epoch 46/220\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 130.4827 - mae: 9.1976 - val_loss: 134.2238 - val_mae: 9.3188\n",
      "Epoch 47/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 128.8433 - mae: 9.1269 - val_loss: 132.2333 - val_mae: 9.2339\n",
      "Epoch 48/220\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 126.6540 - mae: 9.0544 - val_loss: 131.1383 - val_mae: 9.1852\n",
      "Epoch 49/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 124.7155 - mae: 8.9853 - val_loss: 128.4309 - val_mae: 9.0840\n",
      "Epoch 50/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 122.5375 - mae: 8.9013 - val_loss: 126.3879 - val_mae: 8.9969\n",
      "Epoch 51/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 120.6273 - mae: 8.8264 - val_loss: 124.3958 - val_mae: 8.9025\n",
      "Epoch 52/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 118.5892 - mae: 8.7488 - val_loss: 122.7962 - val_mae: 8.8303\n",
      "Epoch 53/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 116.8712 - mae: 8.6682 - val_loss: 120.1910 - val_mae: 8.7125\n",
      "Epoch 54/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 114.4585 - mae: 8.5770 - val_loss: 118.1072 - val_mae: 8.6368\n",
      "Epoch 55/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 112.8979 - mae: 8.4996 - val_loss: 116.3512 - val_mae: 8.5680\n",
      "Epoch 56/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 111.2226 - mae: 8.4216 - val_loss: 115.7972 - val_mae: 8.5177\n",
      "Epoch 57/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 109.3011 - mae: 8.3502 - val_loss: 112.9893 - val_mae: 8.4378\n",
      "Epoch 58/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 107.5487 - mae: 8.2673 - val_loss: 111.5892 - val_mae: 8.3524\n",
      "Epoch 59/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 105.9926 - mae: 8.1973 - val_loss: 110.0700 - val_mae: 8.2989\n",
      "Epoch 60/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 104.5538 - mae: 8.1267 - val_loss: 108.4607 - val_mae: 8.2313\n",
      "Epoch 61/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 102.9536 - mae: 8.0510 - val_loss: 107.3105 - val_mae: 8.1829\n",
      "Epoch 62/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 101.4794 - mae: 7.9837 - val_loss: 104.5642 - val_mae: 8.0840\n",
      "Epoch 63/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 99.7059 - mae: 7.9043 - val_loss: 103.4780 - val_mae: 8.0104\n",
      "Epoch 64/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 98.0065 - mae: 7.8292 - val_loss: 101.8938 - val_mae: 7.9568\n",
      "Epoch 65/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 96.2553 - mae: 7.7630 - val_loss: 100.2764 - val_mae: 7.9049\n",
      "Epoch 66/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 94.7550 - mae: 7.6914 - val_loss: 99.0195 - val_mae: 7.8370\n",
      "Epoch 67/220\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 92.8246 - mae: 7.6019 - val_loss: 97.5811 - val_mae: 7.7929\n",
      "Epoch 68/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 91.9924 - mae: 7.5597 - val_loss: 96.5174 - val_mae: 7.7301\n",
      "Epoch 69/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 90.4454 - mae: 7.4964 - val_loss: 95.0299 - val_mae: 7.6814\n",
      "Epoch 70/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 88.9537 - mae: 7.4348 - val_loss: 93.6664 - val_mae: 7.6043\n",
      "Epoch 71/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 87.6815 - mae: 7.3794 - val_loss: 92.9030 - val_mae: 7.5549\n",
      "Epoch 72/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 86.4279 - mae: 7.3158 - val_loss: 91.2705 - val_mae: 7.4827\n",
      "Epoch 73/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 85.3052 - mae: 7.2633 - val_loss: 89.9464 - val_mae: 7.4263\n",
      "Epoch 74/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 84.0638 - mae: 7.2149 - val_loss: 88.4986 - val_mae: 7.3723\n",
      "Epoch 75/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 82.8481 - mae: 7.1623 - val_loss: 86.9120 - val_mae: 7.3068\n",
      "Epoch 76/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 81.8424 - mae: 7.1083 - val_loss: 85.5187 - val_mae: 7.2423\n",
      "Epoch 77/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 80.2829 - mae: 7.0382 - val_loss: 83.5671 - val_mae: 7.1602\n",
      "Epoch 78/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 78.9199 - mae: 6.9753 - val_loss: 82.9777 - val_mae: 7.1219\n",
      "Epoch 79/220\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 78.0700 - mae: 6.9330 - val_loss: 81.6343 - val_mae: 7.0753\n",
      "Epoch 80/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 76.4772 - mae: 6.8751 - val_loss: 80.2824 - val_mae: 7.0156\n",
      "Epoch 81/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 75.7923 - mae: 6.8280 - val_loss: 79.5827 - val_mae: 6.9635\n",
      "Epoch 82/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 74.7051 - mae: 6.8008 - val_loss: 79.0474 - val_mae: 6.9548\n",
      "Epoch 83/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 73.6561 - mae: 6.7382 - val_loss: 78.0497 - val_mae: 6.8985\n",
      "Epoch 84/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 72.5510 - mae: 6.6858 - val_loss: 77.4249 - val_mae: 6.8746\n",
      "Epoch 85/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 71.6125 - mae: 6.6556 - val_loss: 76.5684 - val_mae: 6.8568\n",
      "Epoch 86/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 70.6830 - mae: 6.6073 - val_loss: 76.1219 - val_mae: 6.8096\n",
      "Epoch 87/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 69.8591 - mae: 6.5654 - val_loss: 75.2136 - val_mae: 6.7668\n",
      "Epoch 88/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 69.1470 - mae: 6.5314 - val_loss: 74.9157 - val_mae: 6.7425\n",
      "Epoch 89/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 68.5014 - mae: 6.4860 - val_loss: 75.0443 - val_mae: 6.7290\n",
      "Epoch 90/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 67.4468 - mae: 6.4368 - val_loss: 73.6318 - val_mae: 6.6748\n",
      "Epoch 91/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 66.8923 - mae: 6.4214 - val_loss: 73.6052 - val_mae: 6.6586\n",
      "Epoch 92/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 66.0265 - mae: 6.3709 - val_loss: 73.2766 - val_mae: 6.6432\n",
      "Epoch 93/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 65.3011 - mae: 6.3360 - val_loss: 72.5176 - val_mae: 6.6262\n",
      "Epoch 94/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 64.8728 - mae: 6.3168 - val_loss: 72.0459 - val_mae: 6.6059\n",
      "Epoch 95/220\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 64.4998 - mae: 6.3010 - val_loss: 71.4896 - val_mae: 6.5838\n",
      "Epoch 96/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 63.5301 - mae: 6.2490 - val_loss: 71.3239 - val_mae: 6.5391\n",
      "Epoch 97/220\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 63.0520 - mae: 6.2220 - val_loss: 71.0834 - val_mae: 6.5405\n",
      "Epoch 98/220\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 62.3754 - mae: 6.1928 - val_loss: 70.3876 - val_mae: 6.5091\n",
      "Epoch 99/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 62.0189 - mae: 6.1773 - val_loss: 69.6950 - val_mae: 6.4737\n",
      "Epoch 100/220\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 61.3494 - mae: 6.1311 - val_loss: 70.4257 - val_mae: 6.4866\n",
      "Epoch 101/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 60.7933 - mae: 6.1076 - val_loss: 69.2673 - val_mae: 6.4548\n",
      "Epoch 102/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 60.3117 - mae: 6.0744 - val_loss: 69.4141 - val_mae: 6.4069\n",
      "Epoch 103/220\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 59.7617 - mae: 6.0433 - val_loss: 68.9610 - val_mae: 6.4050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 104/220\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 59.2315 - mae: 6.0300 - val_loss: 68.2655 - val_mae: 6.3757\n",
      "Epoch 105/220\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 58.6161 - mae: 5.9783 - val_loss: 67.9599 - val_mae: 6.3588\n",
      "Epoch 106/220\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 58.0889 - mae: 5.9680 - val_loss: 67.2950 - val_mae: 6.3339\n",
      "Epoch 107/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 57.7033 - mae: 5.9363 - val_loss: 67.1154 - val_mae: 6.3278\n",
      "Epoch 108/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 57.1748 - mae: 5.9257 - val_loss: 66.8417 - val_mae: 6.2973\n",
      "Epoch 109/220\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 56.8273 - mae: 5.8916 - val_loss: 66.8116 - val_mae: 6.2658\n",
      "Epoch 110/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 56.2599 - mae: 5.8618 - val_loss: 66.5039 - val_mae: 6.2634\n",
      "Epoch 111/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 56.1059 - mae: 5.8724 - val_loss: 66.1267 - val_mae: 6.2416\n",
      "Epoch 112/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 55.4775 - mae: 5.8105 - val_loss: 65.7092 - val_mae: 6.2177\n",
      "Epoch 113/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 55.1026 - mae: 5.7946 - val_loss: 65.4555 - val_mae: 6.2135\n",
      "Epoch 114/220\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 54.6686 - mae: 5.7697 - val_loss: 65.1665 - val_mae: 6.1684\n",
      "Epoch 115/220\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 54.4543 - mae: 5.7604 - val_loss: 64.9008 - val_mae: 6.1815\n",
      "Epoch 116/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 53.9322 - mae: 5.7472 - val_loss: 64.8414 - val_mae: 6.1673\n",
      "Epoch 117/220\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 53.6314 - mae: 5.7257 - val_loss: 64.3935 - val_mae: 6.1543\n",
      "Epoch 118/220\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 53.2821 - mae: 5.6850 - val_loss: 64.4944 - val_mae: 6.1036\n",
      "Epoch 119/220\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 52.8594 - mae: 5.6638 - val_loss: 64.2503 - val_mae: 6.1499\n",
      "Epoch 120/220\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 52.5552 - mae: 5.6567 - val_loss: 64.0623 - val_mae: 6.0911\n",
      "Epoch 121/220\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 52.5329 - mae: 5.6501 - val_loss: 63.4791 - val_mae: 6.1184\n",
      "Epoch 122/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 52.2508 - mae: 5.6159 - val_loss: 63.4867 - val_mae: 6.0883\n",
      "Epoch 123/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 51.8952 - mae: 5.6111 - val_loss: 63.3013 - val_mae: 6.0568\n",
      "Epoch 124/220\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 51.5269 - mae: 5.5987 - val_loss: 63.2632 - val_mae: 6.0805\n",
      "Epoch 125/220\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 50.9365 - mae: 5.5503 - val_loss: 63.2055 - val_mae: 6.0470\n",
      "Epoch 126/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 50.7170 - mae: 5.5268 - val_loss: 62.9577 - val_mae: 6.0666\n",
      "Epoch 127/220\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 50.4017 - mae: 5.5166 - val_loss: 63.3324 - val_mae: 6.0556\n",
      "Epoch 128/220\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 50.0656 - mae: 5.4660 - val_loss: 63.0226 - val_mae: 6.0462\n",
      "Epoch 129/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 50.0342 - mae: 5.5079 - val_loss: 62.9630 - val_mae: 6.0346\n",
      "Epoch 130/220\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 49.8960 - mae: 5.4694 - val_loss: 62.3642 - val_mae: 6.0279\n",
      "Epoch 131/220\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 49.2592 - mae: 5.4454 - val_loss: 62.6093 - val_mae: 6.0191\n",
      "Epoch 132/220\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 49.1004 - mae: 5.4268 - val_loss: 62.2613 - val_mae: 6.0137\n",
      "Epoch 133/220\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 48.7751 - mae: 5.4211 - val_loss: 62.5274 - val_mae: 6.0120\n",
      "Epoch 134/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 48.5365 - mae: 5.3869 - val_loss: 62.5577 - val_mae: 5.9897\n",
      "Epoch 135/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 48.2414 - mae: 5.3617 - val_loss: 62.4077 - val_mae: 6.0179\n",
      "Epoch 136/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 48.4133 - mae: 5.3942 - val_loss: 62.2586 - val_mae: 5.9960\n",
      "Epoch 137/220\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 48.2874 - mae: 5.3769 - val_loss: 62.1684 - val_mae: 5.9755\n",
      "Epoch 138/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 47.8035 - mae: 5.3531 - val_loss: 61.7257 - val_mae: 5.9702\n",
      "Epoch 139/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 47.5828 - mae: 5.3475 - val_loss: 61.8626 - val_mae: 5.9913\n",
      "Epoch 140/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 47.2386 - mae: 5.3097 - val_loss: 62.3448 - val_mae: 5.9777\n",
      "Epoch 141/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 47.0556 - mae: 5.2960 - val_loss: 61.7203 - val_mae: 5.9664\n",
      "Epoch 142/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 46.9981 - mae: 5.2985 - val_loss: 61.9580 - val_mae: 5.9868\n",
      "Epoch 143/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 46.7176 - mae: 5.3094 - val_loss: 61.8909 - val_mae: 5.9504\n",
      "Epoch 144/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 46.4650 - mae: 5.2524 - val_loss: 62.3611 - val_mae: 5.9919\n",
      "Epoch 145/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 46.3502 - mae: 5.2841 - val_loss: 61.9354 - val_mae: 5.9569\n",
      "Epoch 146/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 46.1618 - mae: 5.2513 - val_loss: 62.2043 - val_mae: 5.9761\n",
      "Epoch 147/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 45.9946 - mae: 5.2447 - val_loss: 61.9389 - val_mae: 5.9579\n",
      "Epoch 148/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 46.2841 - mae: 5.2514 - val_loss: 61.6622 - val_mae: 5.9659\n",
      "Epoch 149/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 45.7934 - mae: 5.2210 - val_loss: 62.0604 - val_mae: 5.9659\n",
      "Epoch 150/220\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 45.9042 - mae: 5.2310 - val_loss: 61.7503 - val_mae: 5.9294\n",
      "Epoch 151/220\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 45.3637 - mae: 5.2119 - val_loss: 61.6656 - val_mae: 5.9326\n",
      "Epoch 152/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 45.2469 - mae: 5.1909 - val_loss: 61.9806 - val_mae: 5.9428\n",
      "Epoch 153/220\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 45.1113 - mae: 5.1929 - val_loss: 61.4747 - val_mae: 5.9232\n",
      "Epoch 154/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 44.9377 - mae: 5.1869 - val_loss: 61.4177 - val_mae: 5.9062\n",
      "Epoch 155/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 44.6865 - mae: 5.1589 - val_loss: 62.0176 - val_mae: 5.9263\n",
      "Epoch 156/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 44.8904 - mae: 5.1661 - val_loss: 61.4674 - val_mae: 5.9144\n",
      "Epoch 157/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 44.3381 - mae: 5.1313 - val_loss: 61.3047 - val_mae: 5.8862\n",
      "Epoch 158/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 44.2283 - mae: 5.1406 - val_loss: 61.1978 - val_mae: 5.8857\n",
      "Epoch 159/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 44.0743 - mae: 5.1274 - val_loss: 61.4152 - val_mae: 5.8951\n",
      "Epoch 160/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 44.2417 - mae: 5.1430 - val_loss: 62.0440 - val_mae: 5.8869\n",
      "Epoch 161/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 43.9420 - mae: 5.1215 - val_loss: 60.9900 - val_mae: 5.8790\n",
      "Epoch 162/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 43.7400 - mae: 5.1266 - val_loss: 61.0382 - val_mae: 5.8456\n",
      "Epoch 163/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 43.7089 - mae: 5.0902 - val_loss: 60.9083 - val_mae: 5.8405\n",
      "Epoch 164/220\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 3ms/step - loss: 43.7086 - mae: 5.0993 - val_loss: 60.6730 - val_mae: 5.8339\n",
      "Epoch 165/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 43.3485 - mae: 5.0904 - val_loss: 60.9601 - val_mae: 5.8236\n",
      "Epoch 166/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 43.4150 - mae: 5.0794 - val_loss: 60.6997 - val_mae: 5.8319\n",
      "Epoch 167/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 43.1268 - mae: 5.0655 - val_loss: 60.7187 - val_mae: 5.8257\n",
      "Epoch 168/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 43.2629 - mae: 5.0932 - val_loss: 61.3861 - val_mae: 5.8145\n",
      "Epoch 169/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 43.0267 - mae: 5.0578 - val_loss: 60.6681 - val_mae: 5.8234\n",
      "Epoch 170/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 42.7172 - mae: 5.0435 - val_loss: 60.8800 - val_mae: 5.8076\n",
      "Epoch 171/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 42.5998 - mae: 5.0294 - val_loss: 60.6857 - val_mae: 5.8126\n",
      "Epoch 172/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 42.3699 - mae: 5.0260 - val_loss: 60.5426 - val_mae: 5.7933\n",
      "Epoch 173/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 42.3705 - mae: 5.0198 - val_loss: 61.0094 - val_mae: 5.8015\n",
      "Epoch 174/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 42.3887 - mae: 5.0186 - val_loss: 60.1226 - val_mae: 5.7785\n",
      "Epoch 175/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 42.2323 - mae: 5.0190 - val_loss: 60.1417 - val_mae: 5.7587\n",
      "Epoch 176/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 42.2592 - mae: 4.9950 - val_loss: 60.0830 - val_mae: 5.7695\n",
      "Epoch 177/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 41.8676 - mae: 5.0039 - val_loss: 60.0174 - val_mae: 5.7524\n",
      "Epoch 178/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 41.8316 - mae: 4.9830 - val_loss: 59.9947 - val_mae: 5.7458\n",
      "Epoch 179/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 41.7598 - mae: 4.9937 - val_loss: 59.6129 - val_mae: 5.7203\n",
      "Epoch 180/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 41.7000 - mae: 4.9695 - val_loss: 59.6852 - val_mae: 5.7363\n",
      "Epoch 181/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 41.5292 - mae: 4.9816 - val_loss: 59.9772 - val_mae: 5.7373\n",
      "Epoch 182/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 41.1985 - mae: 4.9350 - val_loss: 59.6532 - val_mae: 5.7229\n",
      "Epoch 183/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 41.1212 - mae: 4.9357 - val_loss: 59.3351 - val_mae: 5.7119\n",
      "Epoch 184/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 41.1003 - mae: 4.9442 - val_loss: 59.5203 - val_mae: 5.7099\n",
      "Epoch 185/220\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 41.0009 - mae: 4.9389 - val_loss: 59.3293 - val_mae: 5.7040\n",
      "Epoch 186/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 40.8882 - mae: 4.9181 - val_loss: 59.4693 - val_mae: 5.6900\n",
      "Epoch 187/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 40.8188 - mae: 4.9238 - val_loss: 59.5179 - val_mae: 5.6865\n",
      "Epoch 188/220\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 40.5066 - mae: 4.8835 - val_loss: 59.2266 - val_mae: 5.6740\n",
      "Epoch 189/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 40.2978 - mae: 4.8930 - val_loss: 59.0550 - val_mae: 5.6604\n",
      "Epoch 190/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 40.2954 - mae: 4.8645 - val_loss: 59.3282 - val_mae: 5.6717\n",
      "Epoch 191/220\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 40.2655 - mae: 4.8911 - val_loss: 59.3050 - val_mae: 5.6581\n",
      "Epoch 192/220\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 40.1868 - mae: 4.8362 - val_loss: 58.9603 - val_mae: 5.6615\n",
      "Epoch 193/220\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 40.0246 - mae: 4.8674 - val_loss: 59.0685 - val_mae: 5.6384\n",
      "Epoch 194/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 39.8499 - mae: 4.8331 - val_loss: 58.8688 - val_mae: 5.6307\n",
      "Epoch 195/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 40.4152 - mae: 4.8469 - val_loss: 58.3590 - val_mae: 5.6225\n",
      "Epoch 196/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 39.4042 - mae: 4.8005 - val_loss: 59.0754 - val_mae: 5.6405\n",
      "Epoch 197/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 39.1439 - mae: 4.7933 - val_loss: 58.5070 - val_mae: 5.6235\n",
      "Epoch 198/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 39.0274 - mae: 4.7603 - val_loss: 58.4112 - val_mae: 5.6011\n",
      "Epoch 199/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 38.7686 - mae: 4.7691 - val_loss: 58.3280 - val_mae: 5.5958\n",
      "Epoch 200/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 38.5283 - mae: 4.7254 - val_loss: 58.3455 - val_mae: 5.5976\n",
      "Epoch 201/220\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 38.4322 - mae: 4.7208 - val_loss: 57.8013 - val_mae: 5.5492\n",
      "Epoch 202/220\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 38.2940 - mae: 4.7171 - val_loss: 57.2686 - val_mae: 5.5199\n",
      "Epoch 203/220\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 38.0629 - mae: 4.6738 - val_loss: 57.3787 - val_mae: 5.5476\n",
      "Epoch 204/220\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 38.1126 - mae: 4.7155 - val_loss: 57.3392 - val_mae: 5.5339\n",
      "Epoch 205/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 37.6777 - mae: 4.6593 - val_loss: 56.7781 - val_mae: 5.5010\n",
      "Epoch 206/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 37.6339 - mae: 4.6493 - val_loss: 56.6145 - val_mae: 5.4925\n",
      "Epoch 207/220\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 37.4269 - mae: 4.6619 - val_loss: 56.2330 - val_mae: 5.4809\n",
      "Epoch 208/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 37.2297 - mae: 4.6464 - val_loss: 56.0726 - val_mae: 5.4651\n",
      "Epoch 209/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 37.0696 - mae: 4.6177 - val_loss: 55.7953 - val_mae: 5.4364\n",
      "Epoch 210/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 36.8025 - mae: 4.6091 - val_loss: 55.3946 - val_mae: 5.4214\n",
      "Epoch 211/220\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 36.7860 - mae: 4.6067 - val_loss: 55.2613 - val_mae: 5.4184\n",
      "Epoch 212/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 36.8570 - mae: 4.6120 - val_loss: 55.4427 - val_mae: 5.4334\n",
      "Epoch 213/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 36.3892 - mae: 4.5711 - val_loss: 55.1115 - val_mae: 5.4147\n",
      "Epoch 214/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 36.4944 - mae: 4.5758 - val_loss: 54.7193 - val_mae: 5.4061\n",
      "Epoch 215/220\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 36.3743 - mae: 4.5664 - val_loss: 54.7918 - val_mae: 5.4029\n",
      "Epoch 216/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 36.1381 - mae: 4.5533 - val_loss: 54.1657 - val_mae: 5.3554\n",
      "Epoch 217/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 36.2841 - mae: 4.5781 - val_loss: 54.0055 - val_mae: 5.3432\n",
      "Epoch 218/220\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 36.0682 - mae: 4.5388 - val_loss: 54.3751 - val_mae: 5.3753\n",
      "Epoch 219/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 35.5907 - mae: 4.5265 - val_loss: 53.1908 - val_mae: 5.2937\n",
      "Epoch 220/220\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 35.5298 - mae: 4.5063 - val_loss: 53.2464 - val_mae: 5.2865\n",
      "processing fold # 3\n",
      "Epoch 1/220\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 1625.3640 - mae: 36.5046WARNING:tensorflow:Callbacks method `on_test_batch_begin` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_begin` time: 0.0010s). Check your callbacks.\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 1596.0338 - mae: 36.1756 - val_loss: 1578.5891 - val_mae: 35.8837\n",
      "Epoch 2/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 1577.5958 - mae: 35.9385 - val_loss: 1559.8853 - val_mae: 35.6505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 1561.6038 - mae: 35.7306 - val_loss: 1539.8948 - val_mae: 35.4017\n",
      "Epoch 4/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 1541.2424 - mae: 35.4725 - val_loss: 1511.7023 - val_mae: 35.0329\n",
      "Epoch 5/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 1509.9152 - mae: 35.0515 - val_loss: 1470.2068 - val_mae: 34.4714\n",
      "Epoch 6/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 1464.8656 - mae: 34.4438 - val_loss: 1413.7012 - val_mae: 33.7001\n",
      "Epoch 7/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 1403.7256 - mae: 33.6096 - val_loss: 1345.0807 - val_mae: 32.7331\n",
      "Epoch 8/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 1329.3727 - mae: 32.5696 - val_loss: 1257.6528 - val_mae: 31.4756\n",
      "Epoch 9/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 1237.9414 - mae: 31.2582 - val_loss: 1156.5354 - val_mae: 29.9410\n",
      "Epoch 10/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 1130.0444 - mae: 29.6139 - val_loss: 1037.9951 - val_mae: 28.0513\n",
      "Epoch 11/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 1006.6591 - mae: 27.6300 - val_loss: 906.1117 - val_mae: 25.8250\n",
      "Epoch 12/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 872.0239 - mae: 25.3339 - val_loss: 768.6857 - val_mae: 23.3180\n",
      "Epoch 13/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 733.7198 - mae: 22.8273 - val_loss: 633.6446 - val_mae: 20.7788\n",
      "Epoch 14/220\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 599.2529 - mae: 20.3452 - val_loss: 512.1886 - val_mae: 18.3486\n",
      "Epoch 15/220\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 480.9922 - mae: 17.9752 - val_loss: 403.6416 - val_mae: 15.9965\n",
      "Epoch 16/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 381.3193 - mae: 15.7770 - val_loss: 323.6759 - val_mae: 14.0868\n",
      "Epoch 17/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 307.2826 - mae: 14.0162 - val_loss: 269.0171 - val_mae: 12.8089\n",
      "Epoch 18/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 257.2494 - mae: 12.7014 - val_loss: 234.8691 - val_mae: 12.0430\n",
      "Epoch 19/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 227.2485 - mae: 11.9511 - val_loss: 214.5264 - val_mae: 11.6037\n",
      "Epoch 20/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 208.2339 - mae: 11.4854 - val_loss: 203.8470 - val_mae: 11.3580\n",
      "Epoch 21/220\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 197.8272 - mae: 11.2025 - val_loss: 197.0555 - val_mae: 11.2372\n",
      "Epoch 22/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 191.4142 - mae: 11.0423 - val_loss: 192.2686 - val_mae: 11.1407\n",
      "Epoch 23/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 186.3412 - mae: 10.8916 - val_loss: 188.5025 - val_mae: 11.0519\n",
      "Epoch 24/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 183.1692 - mae: 10.8024 - val_loss: 185.5876 - val_mae: 10.9826\n",
      "Epoch 25/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 179.9885 - mae: 10.7114 - val_loss: 182.5222 - val_mae: 10.9070\n",
      "Epoch 26/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 176.7947 - mae: 10.6296 - val_loss: 180.0879 - val_mae: 10.8409\n",
      "Epoch 27/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 173.9735 - mae: 10.5614 - val_loss: 176.9215 - val_mae: 10.7392\n",
      "Epoch 28/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 171.3985 - mae: 10.4905 - val_loss: 174.4962 - val_mae: 10.6735\n",
      "Epoch 29/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 169.1159 - mae: 10.4264 - val_loss: 172.2444 - val_mae: 10.6035\n",
      "Epoch 30/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 166.8405 - mae: 10.3403 - val_loss: 170.2334 - val_mae: 10.5316\n",
      "Epoch 31/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 164.4739 - mae: 10.2811 - val_loss: 168.3013 - val_mae: 10.4783\n",
      "Epoch 32/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 162.5087 - mae: 10.2356 - val_loss: 166.0115 - val_mae: 10.3986\n",
      "Epoch 33/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 160.5849 - mae: 10.1756 - val_loss: 164.4313 - val_mae: 10.3512\n",
      "Epoch 34/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 158.6997 - mae: 10.1179 - val_loss: 162.6638 - val_mae: 10.2834\n",
      "Epoch 35/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 156.8497 - mae: 10.0563 - val_loss: 161.4205 - val_mae: 10.2435\n",
      "Epoch 36/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 155.0761 - mae: 10.0049 - val_loss: 159.3205 - val_mae: 10.1786\n",
      "Epoch 37/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 153.1036 - mae: 9.9393 - val_loss: 157.6401 - val_mae: 10.1248\n",
      "Epoch 38/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 151.4269 - mae: 9.9016 - val_loss: 156.0918 - val_mae: 10.0859\n",
      "Epoch 39/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 149.9038 - mae: 9.8521 - val_loss: 154.5128 - val_mae: 10.0302\n",
      "Epoch 40/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 148.3631 - mae: 9.8082 - val_loss: 153.0634 - val_mae: 9.9872\n",
      "Epoch 41/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 147.1170 - mae: 9.7479 - val_loss: 152.2652 - val_mae: 9.9534\n",
      "Epoch 42/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 145.5625 - mae: 9.7165 - val_loss: 150.7024 - val_mae: 9.9141\n",
      "Epoch 43/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 144.2030 - mae: 9.6810 - val_loss: 149.5578 - val_mae: 9.8747\n",
      "Epoch 44/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 142.9663 - mae: 9.6482 - val_loss: 148.5541 - val_mae: 9.8403\n",
      "Epoch 45/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 142.0863 - mae: 9.6089 - val_loss: 147.3472 - val_mae: 9.7942\n",
      "Epoch 46/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 140.9814 - mae: 9.5686 - val_loss: 146.9790 - val_mae: 9.7882\n",
      "Epoch 47/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 139.6665 - mae: 9.5397 - val_loss: 145.7528 - val_mae: 9.7528\n",
      "Epoch 48/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 138.6125 - mae: 9.4919 - val_loss: 144.9485 - val_mae: 9.7156\n",
      "Epoch 49/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 137.4886 - mae: 9.4587 - val_loss: 143.9679 - val_mae: 9.6815\n",
      "Epoch 50/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 136.5120 - mae: 9.4317 - val_loss: 142.7930 - val_mae: 9.6577\n",
      "Epoch 51/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 135.6618 - mae: 9.3981 - val_loss: 142.5154 - val_mae: 9.6402\n",
      "Epoch 52/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 134.5523 - mae: 9.3590 - val_loss: 141.6515 - val_mae: 9.6156\n",
      "Epoch 53/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 133.6795 - mae: 9.3449 - val_loss: 140.5893 - val_mae: 9.5802\n",
      "Epoch 54/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 132.5450 - mae: 9.2916 - val_loss: 139.7468 - val_mae: 9.5420\n",
      "Epoch 55/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 131.6860 - mae: 9.2547 - val_loss: 139.0253 - val_mae: 9.5200\n",
      "Epoch 56/220\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 130.6985 - mae: 9.2304 - val_loss: 138.7878 - val_mae: 9.5147\n",
      "Epoch 57/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 129.7336 - mae: 9.1942 - val_loss: 137.5023 - val_mae: 9.4693\n",
      "Epoch 58/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 128.4860 - mae: 9.1528 - val_loss: 136.6166 - val_mae: 9.4343\n",
      "Epoch 59/220\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 127.7970 - mae: 9.1078 - val_loss: 136.2817 - val_mae: 9.4189\n",
      "Epoch 60/220\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 126.6931 - mae: 9.0914 - val_loss: 135.0013 - val_mae: 9.3786\n",
      "Epoch 61/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 125.6699 - mae: 9.0438 - val_loss: 134.4030 - val_mae: 9.3555\n",
      "Epoch 62/220\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 3ms/step - loss: 124.7138 - mae: 8.9967 - val_loss: 133.7624 - val_mae: 9.3255\n",
      "Epoch 63/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 123.7581 - mae: 8.9708 - val_loss: 132.3743 - val_mae: 9.2914\n",
      "Epoch 64/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 122.7732 - mae: 8.9327 - val_loss: 131.9435 - val_mae: 9.2705\n",
      "Epoch 65/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 121.6472 - mae: 8.8961 - val_loss: 131.1615 - val_mae: 9.2425\n",
      "Epoch 66/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 120.7056 - mae: 8.8551 - val_loss: 130.3425 - val_mae: 9.2073\n",
      "Epoch 67/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 119.8606 - mae: 8.8251 - val_loss: 129.0645 - val_mae: 9.1732\n",
      "Epoch 68/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 118.7452 - mae: 8.7714 - val_loss: 128.7238 - val_mae: 9.1536\n",
      "Epoch 69/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 117.4790 - mae: 8.7328 - val_loss: 127.2693 - val_mae: 9.1009\n",
      "Epoch 70/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 116.8904 - mae: 8.7171 - val_loss: 126.7914 - val_mae: 9.0761\n",
      "Epoch 71/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 115.4587 - mae: 8.6406 - val_loss: 125.9481 - val_mae: 9.0329\n",
      "Epoch 72/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 114.6340 - mae: 8.6090 - val_loss: 124.3919 - val_mae: 8.9784\n",
      "Epoch 73/220\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 113.7060 - mae: 8.5603 - val_loss: 124.3242 - val_mae: 8.9643\n",
      "Epoch 74/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 112.5323 - mae: 8.5154 - val_loss: 122.9972 - val_mae: 8.9218\n",
      "Epoch 75/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 111.8214 - mae: 8.4959 - val_loss: 121.7816 - val_mae: 8.8696\n",
      "Epoch 76/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 110.6205 - mae: 8.4649 - val_loss: 120.7189 - val_mae: 8.8339\n",
      "Epoch 77/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 109.6766 - mae: 8.4190 - val_loss: 119.7872 - val_mae: 8.7905\n",
      "Epoch 78/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 108.8660 - mae: 8.3802 - val_loss: 118.8941 - val_mae: 8.7537\n",
      "Epoch 79/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 107.8457 - mae: 8.3265 - val_loss: 118.4397 - val_mae: 8.7099\n",
      "Epoch 80/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 106.8836 - mae: 8.2884 - val_loss: 117.7690 - val_mae: 8.6886\n",
      "Epoch 81/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 105.8923 - mae: 8.2576 - val_loss: 117.1333 - val_mae: 8.6608\n",
      "Epoch 82/220\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 104.9780 - mae: 8.2343 - val_loss: 115.3111 - val_mae: 8.5979\n",
      "Epoch 83/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 103.9404 - mae: 8.1836 - val_loss: 114.8374 - val_mae: 8.5491\n",
      "Epoch 84/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 103.2955 - mae: 8.1462 - val_loss: 113.7234 - val_mae: 8.5112\n",
      "Epoch 85/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 102.4303 - mae: 8.0900 - val_loss: 113.1222 - val_mae: 8.4720\n",
      "Epoch 86/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 101.4322 - mae: 8.0523 - val_loss: 112.4770 - val_mae: 8.4354\n",
      "Epoch 87/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 100.5282 - mae: 8.0244 - val_loss: 111.8723 - val_mae: 8.4128\n",
      "Epoch 88/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 99.6281 - mae: 7.9662 - val_loss: 111.2772 - val_mae: 8.3734\n",
      "Epoch 89/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 98.7327 - mae: 7.9495 - val_loss: 109.8400 - val_mae: 8.3273\n",
      "Epoch 90/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 97.9815 - mae: 7.8871 - val_loss: 109.6510 - val_mae: 8.2960\n",
      "Epoch 91/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 96.8645 - mae: 7.8582 - val_loss: 108.4477 - val_mae: 8.2505\n",
      "Epoch 92/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 96.0947 - mae: 7.8128 - val_loss: 107.6429 - val_mae: 8.2158\n",
      "Epoch 93/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 95.0988 - mae: 7.7779 - val_loss: 106.7791 - val_mae: 8.1725\n",
      "Epoch 94/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 94.4596 - mae: 7.7308 - val_loss: 106.0772 - val_mae: 8.1276\n",
      "Epoch 95/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 93.5108 - mae: 7.6900 - val_loss: 105.2391 - val_mae: 8.0928\n",
      "Epoch 96/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 92.6837 - mae: 7.6510 - val_loss: 104.4514 - val_mae: 8.0557\n",
      "Epoch 97/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 92.1059 - mae: 7.6156 - val_loss: 103.6230 - val_mae: 8.0118\n",
      "Epoch 98/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 91.1157 - mae: 7.5675 - val_loss: 102.9513 - val_mae: 7.9701\n",
      "Epoch 99/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 90.4890 - mae: 7.5353 - val_loss: 101.9395 - val_mae: 7.9332\n",
      "Epoch 100/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 89.7793 - mae: 7.4858 - val_loss: 101.5365 - val_mae: 7.9017\n",
      "Epoch 101/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 88.6907 - mae: 7.4480 - val_loss: 100.8021 - val_mae: 7.8736\n",
      "Epoch 102/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 88.0153 - mae: 7.4261 - val_loss: 99.9013 - val_mae: 7.8465\n",
      "Epoch 103/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 87.3795 - mae: 7.3867 - val_loss: 99.3370 - val_mae: 7.8035\n",
      "Epoch 104/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 86.6266 - mae: 7.3289 - val_loss: 99.2820 - val_mae: 7.7792\n",
      "Epoch 105/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 86.1146 - mae: 7.3199 - val_loss: 97.7348 - val_mae: 7.7220\n",
      "Epoch 106/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 85.0843 - mae: 7.2564 - val_loss: 97.0475 - val_mae: 7.6981\n",
      "Epoch 107/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 84.3817 - mae: 7.2347 - val_loss: 96.5650 - val_mae: 7.6554\n",
      "Epoch 108/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 83.7903 - mae: 7.1884 - val_loss: 96.0470 - val_mae: 7.6348\n",
      "Epoch 109/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 83.1427 - mae: 7.1565 - val_loss: 95.5820 - val_mae: 7.6121\n",
      "Epoch 110/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 82.2331 - mae: 7.1115 - val_loss: 94.7450 - val_mae: 7.5748\n",
      "Epoch 111/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 81.8748 - mae: 7.1069 - val_loss: 94.0372 - val_mae: 7.5398\n",
      "Epoch 112/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 80.8489 - mae: 7.0339 - val_loss: 93.3409 - val_mae: 7.4949\n",
      "Epoch 113/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 80.5740 - mae: 7.0331 - val_loss: 92.4893 - val_mae: 7.4701\n",
      "Epoch 114/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 79.6766 - mae: 6.9838 - val_loss: 92.4528 - val_mae: 7.4471\n",
      "Epoch 115/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 78.9781 - mae: 6.9447 - val_loss: 91.5417 - val_mae: 7.3980\n",
      "Epoch 116/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 78.5850 - mae: 6.9224 - val_loss: 91.1919 - val_mae: 7.3764\n",
      "Epoch 117/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 77.8227 - mae: 6.8753 - val_loss: 90.6259 - val_mae: 7.3541\n",
      "Epoch 118/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 77.1435 - mae: 6.8399 - val_loss: 89.8986 - val_mae: 7.3244\n",
      "Epoch 119/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 76.8702 - mae: 6.8133 - val_loss: 89.2259 - val_mae: 7.2897\n",
      "Epoch 120/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 76.0896 - mae: 6.7746 - val_loss: 89.1535 - val_mae: 7.2721\n",
      "Epoch 121/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 75.5299 - mae: 6.7578 - val_loss: 87.7831 - val_mae: 7.2317\n",
      "Epoch 122/220\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 3ms/step - loss: 74.7995 - mae: 6.7117 - val_loss: 87.8998 - val_mae: 7.2058\n",
      "Epoch 123/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 74.3317 - mae: 6.6850 - val_loss: 86.8285 - val_mae: 7.1784\n",
      "Epoch 124/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 73.9641 - mae: 6.6639 - val_loss: 86.6103 - val_mae: 7.1648\n",
      "Epoch 125/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 73.6521 - mae: 6.6424 - val_loss: 86.0692 - val_mae: 7.1436\n",
      "Epoch 126/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 72.6432 - mae: 6.5803 - val_loss: 85.3863 - val_mae: 7.1012\n",
      "Epoch 127/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 72.2070 - mae: 6.5624 - val_loss: 85.0231 - val_mae: 7.0956\n",
      "Epoch 128/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 71.5408 - mae: 6.5320 - val_loss: 84.7053 - val_mae: 7.0747\n",
      "Epoch 129/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 71.0821 - mae: 6.4977 - val_loss: 84.5489 - val_mae: 7.0638\n",
      "Epoch 130/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 70.5854 - mae: 6.4822 - val_loss: 83.2118 - val_mae: 7.0065\n",
      "Epoch 131/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 70.2372 - mae: 6.4580 - val_loss: 83.3414 - val_mae: 7.0125\n",
      "Epoch 132/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 69.6742 - mae: 6.4284 - val_loss: 82.3861 - val_mae: 6.9632\n",
      "Epoch 133/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 69.3075 - mae: 6.4100 - val_loss: 82.3001 - val_mae: 6.9455\n",
      "Epoch 134/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 69.2246 - mae: 6.3838 - val_loss: 82.4115 - val_mae: 6.9705\n",
      "Epoch 135/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 68.5580 - mae: 6.3642 - val_loss: 80.9917 - val_mae: 6.9084\n",
      "Epoch 136/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 68.6134 - mae: 6.3455 - val_loss: 81.0829 - val_mae: 6.9139\n",
      "Epoch 137/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 67.2997 - mae: 6.3015 - val_loss: 80.4700 - val_mae: 6.8944\n",
      "Epoch 138/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 66.9036 - mae: 6.2807 - val_loss: 79.8510 - val_mae: 6.8514\n",
      "Epoch 139/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 66.5050 - mae: 6.2572 - val_loss: 79.3677 - val_mae: 6.8378\n",
      "Epoch 140/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 66.3039 - mae: 6.2506 - val_loss: 79.0834 - val_mae: 6.8175\n",
      "Epoch 141/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 65.8662 - mae: 6.2084 - val_loss: 78.7803 - val_mae: 6.8071\n",
      "Epoch 142/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 65.6172 - mae: 6.2028 - val_loss: 78.6806 - val_mae: 6.7856\n",
      "Epoch 143/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 65.0758 - mae: 6.1735 - val_loss: 78.0130 - val_mae: 6.7836\n",
      "Epoch 144/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 64.7580 - mae: 6.1431 - val_loss: 77.7207 - val_mae: 6.7517\n",
      "Epoch 145/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 64.3298 - mae: 6.1261 - val_loss: 77.1770 - val_mae: 6.7195\n",
      "Epoch 146/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 63.9274 - mae: 6.1100 - val_loss: 76.5537 - val_mae: 6.6991\n",
      "Epoch 147/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 63.7060 - mae: 6.0964 - val_loss: 76.7273 - val_mae: 6.7106\n",
      "Epoch 148/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 63.2960 - mae: 6.0752 - val_loss: 75.8331 - val_mae: 6.6808\n",
      "Epoch 149/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 62.6467 - mae: 6.0439 - val_loss: 75.7149 - val_mae: 6.6512\n",
      "Epoch 150/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 62.3120 - mae: 6.0143 - val_loss: 75.2495 - val_mae: 6.6396\n",
      "Epoch 151/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 62.0900 - mae: 5.9930 - val_loss: 74.7656 - val_mae: 6.6141\n",
      "Epoch 152/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 61.7445 - mae: 5.9904 - val_loss: 74.4885 - val_mae: 6.6052\n",
      "Epoch 153/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 61.5984 - mae: 5.9647 - val_loss: 74.4798 - val_mae: 6.6027\n",
      "Epoch 154/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 61.3126 - mae: 5.9414 - val_loss: 73.6840 - val_mae: 6.5684\n",
      "Epoch 155/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 60.6929 - mae: 5.9243 - val_loss: 73.3897 - val_mae: 6.5458\n",
      "Epoch 156/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 60.4627 - mae: 5.9152 - val_loss: 72.9262 - val_mae: 6.5336\n",
      "Epoch 157/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 60.1058 - mae: 5.8945 - val_loss: 72.2638 - val_mae: 6.4830\n",
      "Epoch 158/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 59.9165 - mae: 5.8741 - val_loss: 72.2919 - val_mae: 6.5207\n",
      "Epoch 159/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 59.6927 - mae: 5.8607 - val_loss: 71.9002 - val_mae: 6.4711\n",
      "Epoch 160/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 59.3216 - mae: 5.8535 - val_loss: 71.4295 - val_mae: 6.4603\n",
      "Epoch 161/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 58.8242 - mae: 5.8025 - val_loss: 71.3267 - val_mae: 6.4377\n",
      "Epoch 162/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 58.5713 - mae: 5.8080 - val_loss: 70.4718 - val_mae: 6.3988\n",
      "Epoch 163/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 58.2192 - mae: 5.7837 - val_loss: 70.3893 - val_mae: 6.3947\n",
      "Epoch 164/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 58.0442 - mae: 5.7790 - val_loss: 70.1691 - val_mae: 6.3935\n",
      "Epoch 165/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 58.1442 - mae: 5.7626 - val_loss: 70.0092 - val_mae: 6.3907\n",
      "Epoch 166/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 57.5312 - mae: 5.7425 - val_loss: 69.3052 - val_mae: 6.3634\n",
      "Epoch 167/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 57.1599 - mae: 5.7156 - val_loss: 69.5609 - val_mae: 6.3480\n",
      "Epoch 168/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 56.9092 - mae: 5.6990 - val_loss: 68.8640 - val_mae: 6.3309\n",
      "Epoch 169/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 56.6522 - mae: 5.6900 - val_loss: 68.4860 - val_mae: 6.3053\n",
      "Epoch 170/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 56.4326 - mae: 5.6906 - val_loss: 68.2058 - val_mae: 6.3005\n",
      "Epoch 171/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 56.1485 - mae: 5.6726 - val_loss: 68.1228 - val_mae: 6.2874\n",
      "Epoch 172/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 55.7916 - mae: 5.6455 - val_loss: 67.7091 - val_mae: 6.2725\n",
      "Epoch 173/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 55.5232 - mae: 5.6273 - val_loss: 67.6322 - val_mae: 6.2664\n",
      "Epoch 174/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 55.3121 - mae: 5.6163 - val_loss: 67.1958 - val_mae: 6.2335\n",
      "Epoch 175/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 55.1698 - mae: 5.5995 - val_loss: 66.9521 - val_mae: 6.2313\n",
      "Epoch 176/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 54.8161 - mae: 5.5885 - val_loss: 66.5479 - val_mae: 6.2065\n",
      "Epoch 177/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 54.6924 - mae: 5.5914 - val_loss: 66.1847 - val_mae: 6.1962\n",
      "Epoch 178/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 54.4400 - mae: 5.5830 - val_loss: 66.0305 - val_mae: 6.1923\n",
      "Epoch 179/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 54.0190 - mae: 5.5467 - val_loss: 65.5984 - val_mae: 6.1697\n",
      "Epoch 180/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 53.7482 - mae: 5.5244 - val_loss: 65.6007 - val_mae: 6.1585\n",
      "Epoch 181/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 53.5966 - mae: 5.5220 - val_loss: 65.1619 - val_mae: 6.1555\n",
      "Epoch 182/220\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 53.4972 - mae: 5.5341 - val_loss: 64.6517 - val_mae: 6.1256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 183/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 53.1402 - mae: 5.5122 - val_loss: 64.7368 - val_mae: 6.1222\n",
      "Epoch 184/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 53.0724 - mae: 5.4903 - val_loss: 64.4654 - val_mae: 6.1263\n",
      "Epoch 185/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 52.7012 - mae: 5.4803 - val_loss: 64.6010 - val_mae: 6.1047\n",
      "Epoch 186/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 52.5673 - mae: 5.4712 - val_loss: 63.7781 - val_mae: 6.0723\n",
      "Epoch 187/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 52.3732 - mae: 5.4580 - val_loss: 63.9168 - val_mae: 6.0967\n",
      "Epoch 188/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 52.3718 - mae: 5.4603 - val_loss: 64.0021 - val_mae: 6.0804\n",
      "Epoch 189/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 51.8865 - mae: 5.4256 - val_loss: 63.5596 - val_mae: 6.0574\n",
      "Epoch 190/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 51.7338 - mae: 5.4242 - val_loss: 63.0714 - val_mae: 6.0391\n",
      "Epoch 191/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 52.0204 - mae: 5.4338 - val_loss: 62.8079 - val_mae: 6.0351\n",
      "Epoch 192/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 51.7531 - mae: 5.4151 - val_loss: 63.2732 - val_mae: 6.0395\n",
      "Epoch 193/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 51.3115 - mae: 5.4046 - val_loss: 62.6024 - val_mae: 6.0231\n",
      "Epoch 194/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 51.0904 - mae: 5.3798 - val_loss: 62.5038 - val_mae: 5.9962\n",
      "Epoch 195/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 51.0186 - mae: 5.3952 - val_loss: 61.9376 - val_mae: 6.0088\n",
      "Epoch 196/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 50.5657 - mae: 5.3670 - val_loss: 62.1905 - val_mae: 5.9940\n",
      "Epoch 197/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 50.8359 - mae: 5.3769 - val_loss: 62.0562 - val_mae: 6.0112\n",
      "Epoch 198/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 50.5204 - mae: 5.3548 - val_loss: 61.6657 - val_mae: 5.9652\n",
      "Epoch 199/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 50.2439 - mae: 5.3303 - val_loss: 61.4321 - val_mae: 5.9662\n",
      "Epoch 200/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 50.1415 - mae: 5.3386 - val_loss: 61.0451 - val_mae: 5.9578\n",
      "Epoch 201/220\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 49.8495 - mae: 5.3016 - val_loss: 61.2381 - val_mae: 5.9571\n",
      "Epoch 202/220\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 49.9577 - mae: 5.3184 - val_loss: 60.9805 - val_mae: 5.9616\n",
      "Epoch 203/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 49.5700 - mae: 5.3073 - val_loss: 60.5706 - val_mae: 5.9258\n",
      "Epoch 204/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 49.4517 - mae: 5.2900 - val_loss: 60.5018 - val_mae: 5.9163\n",
      "Epoch 205/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 49.3463 - mae: 5.2893 - val_loss: 60.5019 - val_mae: 5.9218\n",
      "Epoch 206/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 49.2498 - mae: 5.2825 - val_loss: 60.3223 - val_mae: 5.9203\n",
      "Epoch 207/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 48.9615 - mae: 5.2770 - val_loss: 59.8393 - val_mae: 5.9059\n",
      "Epoch 208/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 48.6698 - mae: 5.2516 - val_loss: 60.0044 - val_mae: 5.9043\n",
      "Epoch 209/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 48.8107 - mae: 5.2681 - val_loss: 59.4818 - val_mae: 5.8713\n",
      "Epoch 210/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 48.5914 - mae: 5.2424 - val_loss: 59.7019 - val_mae: 5.8785\n",
      "Epoch 211/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 48.4683 - mae: 5.2498 - val_loss: 59.8940 - val_mae: 5.9025\n",
      "Epoch 212/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 48.1620 - mae: 5.2187 - val_loss: 59.0447 - val_mae: 5.8601\n",
      "Epoch 213/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 48.0728 - mae: 5.2033 - val_loss: 59.4596 - val_mae: 5.8624\n",
      "Epoch 214/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 47.6060 - mae: 5.1979 - val_loss: 58.7135 - val_mae: 5.8494\n",
      "Epoch 215/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 47.6104 - mae: 5.1974 - val_loss: 58.6073 - val_mae: 5.8532\n",
      "Epoch 216/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 47.4429 - mae: 5.1872 - val_loss: 58.5803 - val_mae: 5.8367\n",
      "Epoch 217/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 47.1603 - mae: 5.1637 - val_loss: 58.5786 - val_mae: 5.8402\n",
      "Epoch 218/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 47.1359 - mae: 5.1641 - val_loss: 58.4751 - val_mae: 5.8277\n",
      "Epoch 219/220\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 47.1286 - mae: 5.1439 - val_loss: 58.5364 - val_mae: 5.8177\n",
      "Epoch 220/220\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 46.7516 - mae: 5.1498 - val_loss: 58.0004 - val_mae: 5.8243\n"
     ]
    }
   ],
   "source": [
    "k = 4\n",
    "num_val_samples = len(x_train) // k\n",
    "num_epochs = 220\n",
    "all_val_mae = []\n",
    "all_mae = []\n",
    "\n",
    "\n",
    "for i in range(k):\n",
    "    print('processing fold #', i)\n",
    "    val_data = x_train[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "    val_targets = y_train[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "    partialx_train = np.concatenate(\n",
    "    [x_train[:i * num_val_samples],\n",
    "    x_train[(i + 1) * num_val_samples:]],\n",
    "    axis=0)\n",
    "    partialy_train = np.concatenate([y_train[:i * num_val_samples],y_train[(i + 1) * num_val_samples:]],\n",
    "    axis=0)\n",
    "    model = build_model()\n",
    "    history = model.fit(partialx_train, partialy_train,validation_data=(val_data, val_targets),\n",
    "    epochs=num_epochs, batch_size=16, verbose=1)\n",
    "    val_mae_history = history.history['val_mae']\n",
    "    mae_history= history.history['mae']\n",
    "    all_mae.append(mae_history)\n",
    "    all_val_mae.append(val_mae_history)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_mae = [\n",
    "np.mean([x[i] for x in all_mae]) for i in range(num_epochs)]\n",
    "average_val_mae = [\n",
    "np.mean([x[i] for x in all_val_mae]) for i in range(num_epochs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "epochs= range(1, len(average_mae) + 1)\n",
    "plt.plot(epochs, average_mae, 'b',label=' Training')\n",
    "plt.plot(epochs, average_val_mae, 'r', label= 'Validation')\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation MAE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 2ms/step - loss: 49.3121 - mae: 5.3023\n"
     ]
    }
   ],
   "source": [
    "test_mse_score, test_mae_score = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.302292823791504"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_mae_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred= model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[27.133713 ],\n",
       "       [ 9.558396 ],\n",
       "       [79.30924  ],\n",
       "       [60.140587 ],\n",
       "       [15.224433 ],\n",
       "       [44.245964 ],\n",
       "       [59.11906  ],\n",
       "       [21.75445  ],\n",
       "       [76.7532   ],\n",
       "       [46.42123  ],\n",
       "       [17.217176 ],\n",
       "       [46.232414 ],\n",
       "       [40.37963  ],\n",
       "       [17.959545 ],\n",
       "       [60.205456 ],\n",
       "       [70.157745 ],\n",
       "       [39.43622  ],\n",
       "       [35.608276 ],\n",
       "       [53.721916 ],\n",
       "       [42.863903 ],\n",
       "       [70.63759  ],\n",
       "       [31.127934 ],\n",
       "       [36.644463 ],\n",
       "       [49.732338 ],\n",
       "       [16.170622 ],\n",
       "       [24.709034 ],\n",
       "       [64.46958  ],\n",
       "       [23.313913 ],\n",
       "       [70.157745 ],\n",
       "       [69.77224  ],\n",
       "       [18.954243 ],\n",
       "       [45.38864  ],\n",
       "       [25.002106 ],\n",
       "       [34.75573  ],\n",
       "       [18.228645 ],\n",
       "       [11.260299 ],\n",
       "       [41.421494 ],\n",
       "       [27.332325 ],\n",
       "       [29.926191 ],\n",
       "       [30.255863 ],\n",
       "       [51.104454 ],\n",
       "       [39.785774 ],\n",
       "       [29.199028 ],\n",
       "       [42.752205 ],\n",
       "       [63.34508  ],\n",
       "       [42.5958   ],\n",
       "       [22.83651  ],\n",
       "       [37.86122  ],\n",
       "       [34.3215   ],\n",
       "       [45.25663  ],\n",
       "       [45.479836 ],\n",
       "       [26.70449  ],\n",
       "       [31.766685 ],\n",
       "       [43.282516 ],\n",
       "       [57.217545 ],\n",
       "       [48.141953 ],\n",
       "       [44.637646 ],\n",
       "       [56.986908 ],\n",
       "       [64.10895  ],\n",
       "       [46.683018 ],\n",
       "       [36.635826 ],\n",
       "       [19.526093 ],\n",
       "       [61.878998 ],\n",
       "       [39.831028 ],\n",
       "       [17.241936 ],\n",
       "       [59.352455 ],\n",
       "       [40.981037 ],\n",
       "       [25.837788 ],\n",
       "       [13.01164  ],\n",
       "       [15.026973 ],\n",
       "       [15.046041 ],\n",
       "       [25.523317 ],\n",
       "       [46.574028 ],\n",
       "       [24.650705 ],\n",
       "       [35.740356 ],\n",
       "       [31.79863  ],\n",
       "       [33.086067 ],\n",
       "       [13.050575 ],\n",
       "       [31.636368 ],\n",
       "       [37.85359  ],\n",
       "       [12.6935835],\n",
       "       [53.82064  ],\n",
       "       [22.96052  ],\n",
       "       [32.833298 ],\n",
       "       [48.321087 ],\n",
       "       [38.061188 ],\n",
       "       [35.087093 ],\n",
       "       [57.957733 ],\n",
       "       [40.662697 ],\n",
       "       [36.19246  ],\n",
       "       [69.74258  ],\n",
       "       [17.292767 ],\n",
       "       [13.083526 ],\n",
       "       [49.081383 ],\n",
       "       [17.998514 ],\n",
       "       [43.921097 ],\n",
       "       [25.012814 ],\n",
       "       [41.59076  ],\n",
       "       [54.249424 ],\n",
       "       [37.019302 ],\n",
       "       [22.104977 ],\n",
       "       [24.89198  ],\n",
       "       [31.345606 ],\n",
       "       [25.370825 ],\n",
       "       [41.261765 ],\n",
       "       [45.735085 ],\n",
       "       [53.724754 ],\n",
       "       [21.311975 ],\n",
       "       [30.960323 ],\n",
       "       [40.58416  ],\n",
       "       [11.102719 ],\n",
       "       [47.78837  ],\n",
       "       [16.581022 ],\n",
       "       [33.20245  ],\n",
       "       [51.086327 ],\n",
       "       [62.771065 ],\n",
       "       [36.804684 ],\n",
       "       [40.5527   ],\n",
       "       [44.30661  ],\n",
       "       [21.67943  ],\n",
       "       [42.724304 ],\n",
       "       [25.31794  ],\n",
       "       [74.67598  ],\n",
       "       [34.852127 ],\n",
       "       [13.793501 ],\n",
       "       [ 6.761266 ],\n",
       "       [11.391807 ],\n",
       "       [15.61537  ],\n",
       "       [59.550747 ],\n",
       "       [37.051857 ],\n",
       "       [32.84229  ],\n",
       "       [45.929188 ],\n",
       "       [36.405453 ],\n",
       "       [30.515387 ],\n",
       "       [ 6.1905923],\n",
       "       [67.49871  ],\n",
       "       [42.354004 ],\n",
       "       [42.77648  ],\n",
       "       [ 6.330296 ],\n",
       "       [14.498745 ],\n",
       "       [37.50393  ],\n",
       "       [45.791916 ],\n",
       "       [24.023937 ],\n",
       "       [31.628338 ],\n",
       "       [16.32104  ],\n",
       "       [32.62688  ],\n",
       "       [37.47606  ],\n",
       "       [10.802904 ],\n",
       "       [36.806885 ],\n",
       "       [17.271475 ],\n",
       "       [15.510421 ],\n",
       "       [18.36568  ],\n",
       "       [23.742779 ],\n",
       "       [33.441303 ],\n",
       "       [39.21619  ],\n",
       "       [38.768272 ],\n",
       "       [36.831406 ],\n",
       "       [24.219473 ],\n",
       "       [38.030598 ],\n",
       "       [28.229511 ],\n",
       "       [43.03872  ],\n",
       "       [36.654095 ],\n",
       "       [15.52531  ],\n",
       "       [27.721518 ],\n",
       "       [36.0599   ],\n",
       "       [10.795241 ],\n",
       "       [45.39624  ],\n",
       "       [55.629875 ],\n",
       "       [45.388657 ],\n",
       "       [ 8.707074 ],\n",
       "       [40.228085 ],\n",
       "       [41.46339  ],\n",
       "       [31.365662 ],\n",
       "       [38.371666 ],\n",
       "       [11.262544 ],\n",
       "       [14.112148 ],\n",
       "       [21.507141 ],\n",
       "       [44.672127 ],\n",
       "       [31.846252 ],\n",
       "       [49.556084 ],\n",
       "       [21.806732 ],\n",
       "       [25.297438 ],\n",
       "       [14.918513 ],\n",
       "       [46.592556 ],\n",
       "       [28.989931 ],\n",
       "       [40.85949  ],\n",
       "       [42.52672  ],\n",
       "       [48.661194 ],\n",
       "       [18.422619 ],\n",
       "       [61.878998 ],\n",
       "       [29.077225 ],\n",
       "       [68.19973  ],\n",
       "       [57.743286 ],\n",
       "       [36.907085 ],\n",
       "       [ 9.761966 ],\n",
       "       [42.17316  ],\n",
       "       [36.663315 ],\n",
       "       [32.893494 ],\n",
       "       [36.148693 ],\n",
       "       [69.82418  ],\n",
       "       [20.949718 ],\n",
       "       [28.990868 ],\n",
       "       [34.401134 ],\n",
       "       [33.581566 ],\n",
       "       [41.061047 ],\n",
       "       [20.70037  ],\n",
       "       [46.592632 ],\n",
       "       [34.481297 ],\n",
       "       [40.347298 ],\n",
       "       [16.540752 ],\n",
       "       [47.58136  ],\n",
       "       [21.343771 ],\n",
       "       [12.618106 ],\n",
       "       [29.058428 ],\n",
       "       [44.682148 ],\n",
       "       [25.726532 ],\n",
       "       [29.432894 ],\n",
       "       [24.972582 ],\n",
       "       [23.010338 ],\n",
       "       [42.739853 ],\n",
       "       [62.933804 ],\n",
       "       [22.007545 ],\n",
       "       [40.72735  ],\n",
       "       [39.75873  ],\n",
       "       [34.319374 ],\n",
       "       [42.051598 ],\n",
       "       [29.724388 ],\n",
       "       [39.547092 ],\n",
       "       [19.42903  ],\n",
       "       [47.942417 ],\n",
       "       [29.74759  ],\n",
       "       [39.385838 ],\n",
       "       [54.458107 ],\n",
       "       [21.790749 ],\n",
       "       [44.28063  ],\n",
       "       [26.66856  ],\n",
       "       [37.2013   ],\n",
       "       [35.238297 ],\n",
       "       [25.86452  ],\n",
       "       [73.15386  ],\n",
       "       [59.485588 ],\n",
       "       [45.372322 ],\n",
       "       [47.086052 ],\n",
       "       [34.44103  ],\n",
       "       [25.504618 ],\n",
       "       [18.031649 ],\n",
       "       [34.834335 ],\n",
       "       [32.811848 ],\n",
       "       [46.74363  ],\n",
       "       [12.239541 ],\n",
       "       [11.160861 ],\n",
       "       [50.60952  ],\n",
       "       [44.410965 ],\n",
       "       [33.44283  ],\n",
       "       [44.720955 ],\n",
       "       [20.617136 ],\n",
       "       [23.649214 ],\n",
       "       [14.977603 ],\n",
       "       [45.192596 ],\n",
       "       [35.542305 ],\n",
       "       [52.97015  ],\n",
       "       [78.47669  ],\n",
       "       [46.468414 ],\n",
       "       [35.52718  ],\n",
       "       [39.583256 ],\n",
       "       [60.079575 ],\n",
       "       [42.796295 ],\n",
       "       [37.905212 ],\n",
       "       [18.020798 ],\n",
       "       [37.368843 ],\n",
       "       [66.904526 ],\n",
       "       [35.66508  ],\n",
       "       [29.156929 ],\n",
       "       [44.487396 ],\n",
       "       [44.44045  ],\n",
       "       [41.244316 ],\n",
       "       [42.529366 ],\n",
       "       [32.275    ],\n",
       "       [65.467094 ],\n",
       "       [36.81515  ],\n",
       "       [14.557914 ],\n",
       "       [53.982277 ],\n",
       "       [55.246147 ],\n",
       "       [46.4283   ],\n",
       "       [29.698608 ],\n",
       "       [34.46079  ],\n",
       "       [42.227116 ],\n",
       "       [43.750343 ],\n",
       "       [75.55685  ],\n",
       "       [41.35194  ],\n",
       "       [24.765987 ],\n",
       "       [70.890175 ],\n",
       "       [33.04566  ],\n",
       "       [46.696568 ],\n",
       "       [66.8623   ],\n",
       "       [36.81957  ],\n",
       "       [35.388275 ],\n",
       "       [42.34488  ],\n",
       "       [37.431778 ],\n",
       "       [35.882507 ],\n",
       "       [32.590645 ],\n",
       "       [45.32231  ],\n",
       "       [22.277884 ],\n",
       "       [13.317471 ],\n",
       "       [75.54136  ],\n",
       "       [29.032421 ],\n",
       "       [14.402182 ],\n",
       "       [20.34399  ],\n",
       "       [43.777954 ]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "def build_model1():\n",
    "    model1 = models.Sequential()\n",
    "    model1.add(layers.Dense(16, activation='relu',input_shape=(8,)))\n",
    "    \n",
    "    model1.add(layers.Dense(4, activation='relu'))\n",
    "\n",
    "\n",
    "    model1.add(layers.Dense(1, activation='linear'))\n",
    "    model1.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "    return model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/350\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 1394.8267 - mae: 33.4879 - val_loss: 1360.0591 - val_mae: 32.6827\n",
      "Epoch 2/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 1241.4297 - mae: 31.2122 - val_loss: 1165.1969 - val_mae: 29.6940\n",
      "Epoch 3/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 1022.6175 - mae: 27.6595 - val_loss: 906.1445 - val_mae: 25.3634\n",
      "Epoch 4/350\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 755.1663 - mae: 22.8761 - val_loss: 631.9204 - val_mae: 20.3516\n",
      "Epoch 5/350\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 509.5182 - mae: 18.0347 - val_loss: 426.2126 - val_mae: 16.3742\n",
      "Epoch 6/350\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 344.6096 - mae: 14.6246 - val_loss: 310.6513 - val_mae: 13.7655\n",
      "Epoch 7/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 259.2477 - mae: 12.7356 - val_loss: 252.5310 - val_mae: 12.5622\n",
      "Epoch 8/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 219.0561 - mae: 11.7980 - val_loss: 222.9956 - val_mae: 11.8520\n",
      "Epoch 9/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 199.9646 - mae: 11.3412 - val_loss: 206.6705 - val_mae: 11.4870\n",
      "Epoch 10/350\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 188.4980 - mae: 11.1136 - val_loss: 196.2053 - val_mae: 11.2425\n",
      "Epoch 11/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 179.7204 - mae: 10.8955 - val_loss: 188.2806 - val_mae: 11.0349\n",
      "Epoch 12/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 173.3368 - mae: 10.7476 - val_loss: 180.7449 - val_mae: 10.8543\n",
      "Epoch 13/350\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 166.5989 - mae: 10.5285 - val_loss: 174.8253 - val_mae: 10.6732\n",
      "Epoch 14/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 160.6832 - mae: 10.3599 - val_loss: 169.7510 - val_mae: 10.5492\n",
      "Epoch 15/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 156.1318 - mae: 10.2113 - val_loss: 165.0888 - val_mae: 10.4227\n",
      "Epoch 16/350\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 150.8755 - mae: 10.0455 - val_loss: 159.9528 - val_mae: 10.2334\n",
      "Epoch 17/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 146.0747 - mae: 9.8673 - val_loss: 155.3856 - val_mae: 10.0565\n",
      "Epoch 18/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 141.5557 - mae: 9.7107 - val_loss: 151.2051 - val_mae: 9.8984\n",
      "Epoch 19/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 137.6712 - mae: 9.5636 - val_loss: 147.4924 - val_mae: 9.7545\n",
      "Epoch 20/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 133.5479 - mae: 9.3962 - val_loss: 143.5231 - val_mae: 9.6035\n",
      "Epoch 21/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 130.2962 - mae: 9.2759 - val_loss: 139.6509 - val_mae: 9.4317\n",
      "Epoch 22/350\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 126.2925 - mae: 9.1049 - val_loss: 136.1884 - val_mae: 9.3042\n",
      "Epoch 23/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 122.6465 - mae: 8.9968 - val_loss: 133.2473 - val_mae: 9.1863\n",
      "Epoch 24/350\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 119.2143 - mae: 8.8312 - val_loss: 128.9456 - val_mae: 8.9987\n",
      "Epoch 25/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 116.4764 - mae: 8.6917 - val_loss: 126.0089 - val_mae: 8.9218\n",
      "Epoch 26/350\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 112.4260 - mae: 8.5503 - val_loss: 122.5975 - val_mae: 8.7500\n",
      "Epoch 27/350\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 109.9586 - mae: 8.4241 - val_loss: 119.8078 - val_mae: 8.6161\n",
      "Epoch 28/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 106.1857 - mae: 8.2763 - val_loss: 116.8080 - val_mae: 8.4773\n",
      "Epoch 29/350\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 103.0414 - mae: 8.1313 - val_loss: 113.7891 - val_mae: 8.3782\n",
      "Epoch 30/350\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 100.1329 - mae: 8.0002 - val_loss: 110.8876 - val_mae: 8.2517\n",
      "Epoch 31/350\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 97.5910 - mae: 7.8898 - val_loss: 108.1108 - val_mae: 8.1262\n",
      "Epoch 32/350\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 94.7238 - mae: 7.7520 - val_loss: 105.4984 - val_mae: 8.0178\n",
      "Epoch 33/350\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 92.3776 - mae: 7.6177 - val_loss: 102.6833 - val_mae: 7.9014\n",
      "Epoch 34/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 89.8502 - mae: 7.5105 - val_loss: 99.8890 - val_mae: 7.7734\n",
      "Epoch 35/350\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 87.1483 - mae: 7.3733 - val_loss: 98.0916 - val_mae: 7.6795\n",
      "Epoch 36/350\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 85.0168 - mae: 7.2580 - val_loss: 95.9534 - val_mae: 7.5962\n",
      "Epoch 37/350\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 83.0774 - mae: 7.1556 - val_loss: 94.2601 - val_mae: 7.4997\n",
      "Epoch 38/350\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 80.8787 - mae: 7.0412 - val_loss: 92.1283 - val_mae: 7.3919\n",
      "Epoch 39/350\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 78.9293 - mae: 6.9489 - val_loss: 90.0600 - val_mae: 7.2984\n",
      "Epoch 40/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 77.2458 - mae: 6.8673 - val_loss: 88.4405 - val_mae: 7.2308\n",
      "Epoch 41/350\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 75.5210 - mae: 6.7702 - val_loss: 86.0629 - val_mae: 7.1213\n",
      "Epoch 42/350\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 73.2764 - mae: 6.6452 - val_loss: 84.2525 - val_mae: 7.0343\n",
      "Epoch 43/350\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 71.7557 - mae: 6.5764 - val_loss: 82.7834 - val_mae: 6.9462\n",
      "Epoch 44/350\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 69.9990 - mae: 6.4785 - val_loss: 81.6217 - val_mae: 6.8938\n",
      "Epoch 45/350\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 68.4674 - mae: 6.3715 - val_loss: 80.3219 - val_mae: 6.8328\n",
      "Epoch 46/350\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 66.3252 - mae: 6.2741 - val_loss: 78.9507 - val_mae: 6.7654\n",
      "Epoch 47/350\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 65.1946 - mae: 6.2177 - val_loss: 76.0053 - val_mae: 6.6679\n",
      "Epoch 48/350\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 63.4339 - mae: 6.1053 - val_loss: 75.0071 - val_mae: 6.6301\n",
      "Epoch 49/350\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 61.8747 - mae: 6.0453 - val_loss: 73.9506 - val_mae: 6.5256\n",
      "Epoch 50/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 60.4362 - mae: 5.9803 - val_loss: 72.6341 - val_mae: 6.4983\n",
      "Epoch 51/350\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 58.8103 - mae: 5.8638 - val_loss: 71.7417 - val_mae: 6.4483\n",
      "Epoch 52/350\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 57.6069 - mae: 5.8217 - val_loss: 70.8360 - val_mae: 6.3971\n",
      "Epoch 53/350\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 56.2603 - mae: 5.7340 - val_loss: 69.8335 - val_mae: 6.3294\n",
      "Epoch 54/350\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 54.9143 - mae: 5.6479 - val_loss: 69.1165 - val_mae: 6.2980\n",
      "Epoch 55/350\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 53.6524 - mae: 5.5831 - val_loss: 68.1942 - val_mae: 6.2333\n",
      "Epoch 56/350\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 52.8515 - mae: 5.5394 - val_loss: 67.8022 - val_mae: 6.2086\n",
      "Epoch 57/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 52.4982 - mae: 5.5378 - val_loss: 66.7821 - val_mae: 6.1066\n",
      "Epoch 58/350\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 50.9161 - mae: 5.4305 - val_loss: 65.7290 - val_mae: 6.0975\n",
      "Epoch 59/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 49.7468 - mae: 5.3354 - val_loss: 64.3525 - val_mae: 6.0398\n",
      "Epoch 60/350\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 48.9548 - mae: 5.3176 - val_loss: 64.2660 - val_mae: 6.0334\n",
      "Epoch 61/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 0s 5ms/step - loss: 48.4102 - mae: 5.2874 - val_loss: 63.3803 - val_mae: 5.9858\n",
      "Epoch 62/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 47.4616 - mae: 5.2011 - val_loss: 63.6781 - val_mae: 5.9858\n",
      "Epoch 63/350\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 47.1472 - mae: 5.1989 - val_loss: 62.1044 - val_mae: 5.9328\n",
      "Epoch 64/350\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 46.3901 - mae: 5.1356 - val_loss: 61.8063 - val_mae: 5.8949\n",
      "Epoch 65/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 46.0607 - mae: 5.1217 - val_loss: 61.7461 - val_mae: 5.8640\n",
      "Epoch 66/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 45.0668 - mae: 5.0683 - val_loss: 62.6066 - val_mae: 5.9207\n",
      "Epoch 67/350\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 44.7512 - mae: 5.0391 - val_loss: 61.5743 - val_mae: 5.8789\n",
      "Epoch 68/350\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 44.6564 - mae: 5.0723 - val_loss: 60.1005 - val_mae: 5.8024\n",
      "Epoch 69/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 43.5844 - mae: 4.9702 - val_loss: 59.4171 - val_mae: 5.7829\n",
      "Epoch 70/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 43.9466 - mae: 5.0231 - val_loss: 59.9131 - val_mae: 5.8203\n",
      "Epoch 71/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 42.6929 - mae: 4.9237 - val_loss: 58.7034 - val_mae: 5.7367\n",
      "Epoch 72/350\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 42.7982 - mae: 4.9275 - val_loss: 59.9944 - val_mae: 5.8234\n",
      "Epoch 73/350\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 41.7695 - mae: 4.8536 - val_loss: 58.4909 - val_mae: 5.7547\n",
      "Epoch 74/350\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 41.6604 - mae: 4.8508 - val_loss: 59.2363 - val_mae: 5.7836\n",
      "Epoch 75/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 41.1899 - mae: 4.8131 - val_loss: 59.0322 - val_mae: 5.8034\n",
      "Epoch 76/350\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 40.8100 - mae: 4.8194 - val_loss: 58.2238 - val_mae: 5.7483\n",
      "Epoch 77/350\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 40.9165 - mae: 4.7981 - val_loss: 58.2480 - val_mae: 5.7376\n",
      "Epoch 78/350\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 40.4666 - mae: 4.7882 - val_loss: 59.4537 - val_mae: 5.7955\n",
      "Epoch 79/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 40.1615 - mae: 4.7752 - val_loss: 57.2650 - val_mae: 5.7281\n",
      "Epoch 80/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 39.7780 - mae: 4.7365 - val_loss: 57.5006 - val_mae: 5.6683\n",
      "Epoch 81/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 39.6591 - mae: 4.7465 - val_loss: 57.6324 - val_mae: 5.6894\n",
      "Epoch 82/350\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 39.0671 - mae: 4.7211 - val_loss: 58.0546 - val_mae: 5.7158\n",
      "Epoch 83/350\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 39.3311 - mae: 4.7227 - val_loss: 58.3700 - val_mae: 5.7285\n",
      "Epoch 84/350\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 38.9929 - mae: 4.6658 - val_loss: 56.9430 - val_mae: 5.6539\n",
      "Epoch 85/350\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 38.7044 - mae: 4.6828 - val_loss: 56.3698 - val_mae: 5.6173\n",
      "Epoch 86/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 38.4641 - mae: 4.6623 - val_loss: 57.1968 - val_mae: 5.6813\n",
      "Epoch 87/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 38.4908 - mae: 4.6853 - val_loss: 56.8495 - val_mae: 5.6434\n",
      "Epoch 88/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 38.2388 - mae: 4.6619 - val_loss: 57.1296 - val_mae: 5.6550\n",
      "Epoch 89/350\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 37.8902 - mae: 4.6321 - val_loss: 56.7854 - val_mae: 5.6438\n",
      "Epoch 90/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 37.8112 - mae: 4.6522 - val_loss: 56.4624 - val_mae: 5.6156\n",
      "Epoch 91/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 37.8860 - mae: 4.6565 - val_loss: 56.8754 - val_mae: 5.6383\n",
      "Epoch 92/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 37.5852 - mae: 4.6200 - val_loss: 56.1209 - val_mae: 5.5883\n",
      "Epoch 93/350\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 37.3258 - mae: 4.6122 - val_loss: 56.1296 - val_mae: 5.6378\n",
      "Epoch 94/350\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 37.3712 - mae: 4.6317 - val_loss: 55.6717 - val_mae: 5.5939\n",
      "Epoch 95/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 37.0318 - mae: 4.6047 - val_loss: 56.8308 - val_mae: 5.6308\n",
      "Epoch 96/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 36.7933 - mae: 4.6105 - val_loss: 55.7191 - val_mae: 5.5952\n",
      "Epoch 97/350\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 37.0264 - mae: 4.5952 - val_loss: 55.8400 - val_mae: 5.5554\n",
      "Epoch 98/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 36.8482 - mae: 4.5784 - val_loss: 56.4443 - val_mae: 5.6258\n",
      "Epoch 99/350\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 36.7124 - mae: 4.5883 - val_loss: 56.2680 - val_mae: 5.6076\n",
      "Epoch 100/350\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 36.5692 - mae: 4.5814 - val_loss: 56.7483 - val_mae: 5.6143\n",
      "Epoch 101/350\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 36.3598 - mae: 4.5988 - val_loss: 55.3656 - val_mae: 5.5561\n",
      "Epoch 102/350\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 36.5064 - mae: 4.5842 - val_loss: 56.0264 - val_mae: 5.5882\n",
      "Epoch 103/350\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 36.1937 - mae: 4.5770 - val_loss: 56.3555 - val_mae: 5.6004\n",
      "Epoch 104/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 36.6640 - mae: 4.5966 - val_loss: 56.5297 - val_mae: 5.6085\n",
      "Epoch 105/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 36.4514 - mae: 4.5880 - val_loss: 56.2530 - val_mae: 5.5765\n",
      "Epoch 106/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 36.2180 - mae: 4.5963 - val_loss: 56.3062 - val_mae: 5.6065\n",
      "Epoch 107/350\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 35.9959 - mae: 4.5888 - val_loss: 55.9766 - val_mae: 5.5628\n",
      "Epoch 108/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 35.8921 - mae: 4.5409 - val_loss: 55.0641 - val_mae: 5.5242\n",
      "Epoch 109/350\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 35.9873 - mae: 4.5853 - val_loss: 55.5261 - val_mae: 5.5406\n",
      "Epoch 110/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 35.8012 - mae: 4.5507 - val_loss: 57.0010 - val_mae: 5.6084\n",
      "Epoch 111/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 35.6984 - mae: 4.5431 - val_loss: 58.8049 - val_mae: 5.6768\n",
      "Epoch 112/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 35.7906 - mae: 4.5673 - val_loss: 55.4159 - val_mae: 5.5380\n",
      "Epoch 113/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 35.7736 - mae: 4.5368 - val_loss: 55.6670 - val_mae: 5.5747\n",
      "Epoch 114/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 35.3949 - mae: 4.5357 - val_loss: 55.5739 - val_mae: 5.5676\n",
      "Epoch 115/350\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 35.4143 - mae: 4.5436 - val_loss: 56.1558 - val_mae: 5.5404\n",
      "Epoch 116/350\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 35.4165 - mae: 4.5617 - val_loss: 54.7573 - val_mae: 5.5025\n",
      "Epoch 117/350\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 35.5530 - mae: 4.5298 - val_loss: 55.1460 - val_mae: 5.5030\n",
      "Epoch 118/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 35.2435 - mae: 4.5278 - val_loss: 54.7922 - val_mae: 5.5085\n",
      "Epoch 119/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 34.9650 - mae: 4.5225 - val_loss: 55.7244 - val_mae: 5.5521\n",
      "Epoch 120/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 35.2079 - mae: 4.5527 - val_loss: 56.1387 - val_mae: 5.5416\n",
      "Epoch 121/350\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 34.8631 - mae: 4.5089 - val_loss: 55.7519 - val_mae: 5.5528\n",
      "Epoch 122/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 0s 3ms/step - loss: 34.9928 - mae: 4.5333 - val_loss: 55.7494 - val_mae: 5.5422\n",
      "Epoch 123/350\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 34.8709 - mae: 4.5224 - val_loss: 54.9448 - val_mae: 5.5516\n",
      "Epoch 124/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 34.7464 - mae: 4.4977 - val_loss: 54.4004 - val_mae: 5.5118\n",
      "Epoch 125/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 34.6800 - mae: 4.5164 - val_loss: 55.0514 - val_mae: 5.5327\n",
      "Epoch 126/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 34.6208 - mae: 4.5012 - val_loss: 54.6472 - val_mae: 5.5339\n",
      "Epoch 127/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 34.8873 - mae: 4.5093 - val_loss: 54.4851 - val_mae: 5.4820\n",
      "Epoch 128/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 34.6294 - mae: 4.5202 - val_loss: 55.5322 - val_mae: 5.5045\n",
      "Epoch 129/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 34.5736 - mae: 4.4965 - val_loss: 56.7687 - val_mae: 5.5699\n",
      "Epoch 130/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 34.6208 - mae: 4.5449 - val_loss: 55.1878 - val_mae: 5.4951\n",
      "Epoch 131/350\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 34.0357 - mae: 4.4687 - val_loss: 54.4836 - val_mae: 5.4823\n",
      "Epoch 132/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 34.2535 - mae: 4.4932 - val_loss: 54.5610 - val_mae: 5.4850\n",
      "Epoch 133/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 34.4302 - mae: 4.5584 - val_loss: 53.3170 - val_mae: 5.4230\n",
      "Epoch 134/350\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 34.2664 - mae: 4.4796 - val_loss: 54.6631 - val_mae: 5.4834\n",
      "Epoch 135/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 34.4803 - mae: 4.5295 - val_loss: 54.1303 - val_mae: 5.4792\n",
      "Epoch 136/350\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 33.8271 - mae: 4.4579 - val_loss: 55.1744 - val_mae: 5.4636\n",
      "Epoch 137/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 33.8469 - mae: 4.4416 - val_loss: 54.4423 - val_mae: 5.4915\n",
      "Epoch 138/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 33.8240 - mae: 4.4702 - val_loss: 54.9149 - val_mae: 5.5148\n",
      "Epoch 139/350\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 33.5247 - mae: 4.4748 - val_loss: 55.1519 - val_mae: 5.4701\n",
      "Epoch 140/350\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 33.8513 - mae: 4.4628 - val_loss: 55.2805 - val_mae: 5.5058\n",
      "Epoch 141/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 33.7552 - mae: 4.4697 - val_loss: 55.9401 - val_mae: 5.4971\n",
      "Epoch 142/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 33.3030 - mae: 4.4223 - val_loss: 56.0250 - val_mae: 5.5355\n",
      "Epoch 143/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 33.6435 - mae: 4.4772 - val_loss: 55.6660 - val_mae: 5.4935\n",
      "Epoch 144/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 33.5679 - mae: 4.4338 - val_loss: 55.5794 - val_mae: 5.5297\n",
      "Epoch 145/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 33.2027 - mae: 4.4775 - val_loss: 53.0934 - val_mae: 5.4084\n",
      "Epoch 146/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 33.5787 - mae: 4.4670 - val_loss: 54.8026 - val_mae: 5.4618\n",
      "Epoch 147/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 33.1360 - mae: 4.4218 - val_loss: 54.6474 - val_mae: 5.4241\n",
      "Epoch 148/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 33.4257 - mae: 4.4549 - val_loss: 56.2750 - val_mae: 5.5349\n",
      "Epoch 149/350\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 33.4093 - mae: 4.4256 - val_loss: 54.4628 - val_mae: 5.4714\n",
      "Epoch 150/350\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 33.3411 - mae: 4.4634 - val_loss: 55.2967 - val_mae: 5.4730\n",
      "Epoch 151/350\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 33.0933 - mae: 4.3984 - val_loss: 53.8187 - val_mae: 5.3852\n",
      "Epoch 152/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 32.8388 - mae: 4.4204 - val_loss: 54.2664 - val_mae: 5.4562\n",
      "Epoch 153/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 32.9475 - mae: 4.4232 - val_loss: 53.8382 - val_mae: 5.4208\n",
      "Epoch 154/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 33.0863 - mae: 4.4104 - val_loss: 54.8915 - val_mae: 5.4900\n",
      "Epoch 155/350\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 33.0976 - mae: 4.4542 - val_loss: 53.8654 - val_mae: 5.4923\n",
      "Epoch 156/350\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 32.9165 - mae: 4.4242 - val_loss: 53.5381 - val_mae: 5.4640\n",
      "Epoch 157/350\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 32.7814 - mae: 4.4147 - val_loss: 54.8996 - val_mae: 5.4759\n",
      "Epoch 158/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 32.8212 - mae: 4.4001 - val_loss: 55.2577 - val_mae: 5.4919\n",
      "Epoch 159/350\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 33.0897 - mae: 4.4258 - val_loss: 54.9288 - val_mae: 5.4833\n",
      "Epoch 160/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 32.5639 - mae: 4.3900 - val_loss: 54.8239 - val_mae: 5.4753\n",
      "Epoch 161/350\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 32.9127 - mae: 4.4315 - val_loss: 54.3579 - val_mae: 5.4801\n",
      "Epoch 162/350\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 32.5090 - mae: 4.4121 - val_loss: 54.2516 - val_mae: 5.4284\n",
      "Epoch 163/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 32.8750 - mae: 4.4042 - val_loss: 54.3615 - val_mae: 5.4490\n",
      "Epoch 164/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 32.6530 - mae: 4.4266 - val_loss: 53.7540 - val_mae: 5.4035\n",
      "Epoch 165/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 32.6474 - mae: 4.3918 - val_loss: 54.4538 - val_mae: 5.4766\n",
      "Epoch 166/350\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 32.4995 - mae: 4.3801 - val_loss: 55.4704 - val_mae: 5.4848\n",
      "Epoch 167/350\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 32.7698 - mae: 4.4069 - val_loss: 53.4435 - val_mae: 5.4580\n",
      "Epoch 168/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 32.5222 - mae: 4.4035 - val_loss: 53.9125 - val_mae: 5.4330\n",
      "Epoch 169/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 32.5376 - mae: 4.3942 - val_loss: 53.8943 - val_mae: 5.4479\n",
      "Epoch 170/350\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 32.7160 - mae: 4.4291 - val_loss: 55.0297 - val_mae: 5.4488\n",
      "Epoch 171/350\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 32.2373 - mae: 4.3847 - val_loss: 54.7399 - val_mae: 5.4229\n",
      "Epoch 172/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 32.4572 - mae: 4.3650 - val_loss: 55.4809 - val_mae: 5.4604\n",
      "Epoch 173/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 32.3806 - mae: 4.4045 - val_loss: 54.5322 - val_mae: 5.4532\n",
      "Epoch 174/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 32.4008 - mae: 4.4136 - val_loss: 54.1298 - val_mae: 5.4252\n",
      "Epoch 175/350\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 32.1007 - mae: 4.3656 - val_loss: 54.2231 - val_mae: 5.4272\n",
      "Epoch 176/350\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 32.1135 - mae: 4.3686 - val_loss: 53.7271 - val_mae: 5.4468\n",
      "Epoch 177/350\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 32.3310 - mae: 4.3717 - val_loss: 54.8320 - val_mae: 5.4384\n",
      "Epoch 178/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 32.1112 - mae: 4.3883 - val_loss: 52.8804 - val_mae: 5.3808\n",
      "Epoch 179/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 32.0620 - mae: 4.3691 - val_loss: 56.1965 - val_mae: 5.5319\n",
      "Epoch 180/350\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 32.0431 - mae: 4.3705 - val_loss: 53.8388 - val_mae: 5.3995\n",
      "Epoch 181/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 32.0520 - mae: 4.3588 - val_loss: 52.9079 - val_mae: 5.4144\n",
      "Epoch 182/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 32.0105 - mae: 4.3773 - val_loss: 54.9203 - val_mae: 5.4342\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 183/350\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 32.1230 - mae: 4.3441 - val_loss: 53.7405 - val_mae: 5.3848\n",
      "Epoch 184/350\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 32.2521 - mae: 4.3786 - val_loss: 53.4270 - val_mae: 5.3682\n",
      "Epoch 185/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 32.1442 - mae: 4.3967 - val_loss: 53.7169 - val_mae: 5.3962\n",
      "Epoch 186/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 32.2510 - mae: 4.3480 - val_loss: 55.4839 - val_mae: 5.4847\n",
      "Epoch 187/350\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 31.8835 - mae: 4.3614 - val_loss: 53.4749 - val_mae: 5.3915\n",
      "Epoch 188/350\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 32.1882 - mae: 4.3740 - val_loss: 53.3213 - val_mae: 5.3829\n",
      "Epoch 189/350\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 31.9949 - mae: 4.3480 - val_loss: 53.1194 - val_mae: 5.4231\n",
      "Epoch 190/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 31.9506 - mae: 4.3926 - val_loss: 54.0445 - val_mae: 5.4144\n",
      "Epoch 191/350\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 32.2314 - mae: 4.3593 - val_loss: 53.7763 - val_mae: 5.4505\n",
      "Epoch 192/350\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 31.8892 - mae: 4.3589 - val_loss: 54.5240 - val_mae: 5.4288\n",
      "Epoch 193/350\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 32.0568 - mae: 4.3594 - val_loss: 53.6606 - val_mae: 5.4381\n",
      "Epoch 194/350\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 31.6009 - mae: 4.3209 - val_loss: 54.3668 - val_mae: 5.4559\n",
      "Epoch 195/350\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 31.9454 - mae: 4.3571 - val_loss: 54.6028 - val_mae: 5.3909\n",
      "Epoch 196/350\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 31.6922 - mae: 4.3419 - val_loss: 56.0661 - val_mae: 5.4744\n",
      "Epoch 197/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 31.6161 - mae: 4.3302 - val_loss: 53.4923 - val_mae: 5.4170\n",
      "Epoch 198/350\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 31.7392 - mae: 4.3418 - val_loss: 55.1424 - val_mae: 5.4254\n",
      "Epoch 199/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 31.7369 - mae: 4.3502 - val_loss: 54.9078 - val_mae: 5.4126\n",
      "Epoch 200/350\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 31.9122 - mae: 4.3480 - val_loss: 54.0642 - val_mae: 5.4111\n",
      "Epoch 201/350\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 31.7318 - mae: 4.3466 - val_loss: 52.9258 - val_mae: 5.3935\n",
      "Epoch 202/350\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 31.8742 - mae: 4.3442 - val_loss: 54.3132 - val_mae: 5.4787\n",
      "Epoch 203/350\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 32.0501 - mae: 4.3918 - val_loss: 53.0675 - val_mae: 5.4191\n",
      "Epoch 204/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 32.2019 - mae: 4.3834 - val_loss: 57.9230 - val_mae: 5.5402\n",
      "Epoch 205/350\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 31.5374 - mae: 4.3008 - val_loss: 53.2635 - val_mae: 5.4040\n",
      "Epoch 206/350\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 31.5856 - mae: 4.3418 - val_loss: 52.9296 - val_mae: 5.4165\n",
      "Epoch 207/350\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 31.4319 - mae: 4.3161 - val_loss: 53.3176 - val_mae: 5.3960\n",
      "Epoch 208/350\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 32.1218 - mae: 4.3666 - val_loss: 53.4282 - val_mae: 5.3804\n",
      "Epoch 209/350\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 31.7454 - mae: 4.3314 - val_loss: 53.2327 - val_mae: 5.3996\n",
      "Epoch 210/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 31.4468 - mae: 4.3355 - val_loss: 55.0856 - val_mae: 5.4700\n",
      "Epoch 211/350\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 31.5143 - mae: 4.3111 - val_loss: 55.8520 - val_mae: 5.4831\n",
      "Epoch 212/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 31.4560 - mae: 4.3232 - val_loss: 55.0756 - val_mae: 5.4441\n",
      "Epoch 213/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 31.6340 - mae: 4.3170 - val_loss: 54.8982 - val_mae: 5.4314\n",
      "Epoch 214/350\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 31.4384 - mae: 4.3256 - val_loss: 54.4545 - val_mae: 5.4296\n",
      "Epoch 215/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 31.3743 - mae: 4.3004 - val_loss: 54.2210 - val_mae: 5.4011\n",
      "Epoch 216/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 31.2160 - mae: 4.3248 - val_loss: 54.6636 - val_mae: 5.4066\n",
      "Epoch 217/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 31.2369 - mae: 4.2955 - val_loss: 53.6345 - val_mae: 5.4043\n",
      "Epoch 218/350\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 31.3655 - mae: 4.3275 - val_loss: 54.1660 - val_mae: 5.3947\n",
      "Epoch 219/350\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 31.2333 - mae: 4.3054 - val_loss: 54.9205 - val_mae: 5.4758\n",
      "Epoch 220/350\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 31.3214 - mae: 4.3295 - val_loss: 54.4475 - val_mae: 5.4212\n",
      "Epoch 221/350\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 31.1234 - mae: 4.3073 - val_loss: 53.5322 - val_mae: 5.3897\n",
      "Epoch 222/350\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 31.3689 - mae: 4.3215 - val_loss: 54.8517 - val_mae: 5.4413\n",
      "Epoch 223/350\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 31.1723 - mae: 4.3018 - val_loss: 54.2508 - val_mae: 5.4130\n",
      "Epoch 224/350\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 31.2506 - mae: 4.3185 - val_loss: 54.3419 - val_mae: 5.3873\n",
      "Epoch 225/350\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 31.1379 - mae: 4.3067 - val_loss: 55.1363 - val_mae: 5.3992\n",
      "Epoch 226/350\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 30.9753 - mae: 4.2886 - val_loss: 54.1960 - val_mae: 5.4184\n",
      "Epoch 227/350\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 30.7117 - mae: 4.2766 - val_loss: 52.8647 - val_mae: 5.4204\n",
      "Epoch 228/350\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 30.8921 - mae: 4.2881 - val_loss: 54.9538 - val_mae: 5.4814\n",
      "Epoch 229/350\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 31.2346 - mae: 4.3369 - val_loss: 52.9243 - val_mae: 5.3478\n",
      "Epoch 230/350\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 31.0404 - mae: 4.3067 - val_loss: 54.9693 - val_mae: 5.3853\n",
      "Epoch 231/350\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 31.0423 - mae: 4.2985 - val_loss: 56.0717 - val_mae: 5.4616\n",
      "Epoch 232/350\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 31.0452 - mae: 4.3130 - val_loss: 54.0499 - val_mae: 5.3848\n",
      "Epoch 233/350\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 31.1847 - mae: 4.3096 - val_loss: 54.1878 - val_mae: 5.4009\n",
      "Epoch 234/350\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 31.1305 - mae: 4.3153 - val_loss: 53.3388 - val_mae: 5.4124\n",
      "Epoch 235/350\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 30.7970 - mae: 4.2797 - val_loss: 55.2132 - val_mae: 5.4074\n",
      "Epoch 236/350\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 31.0387 - mae: 4.2899 - val_loss: 54.1715 - val_mae: 5.3917\n",
      "Epoch 237/350\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 30.9149 - mae: 4.3023 - val_loss: 54.5010 - val_mae: 5.3876\n",
      "Epoch 238/350\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 30.6829 - mae: 4.2951 - val_loss: 52.8662 - val_mae: 5.3827\n",
      "Epoch 239/350\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 31.0987 - mae: 4.2917 - val_loss: 55.6449 - val_mae: 5.4305\n",
      "Epoch 240/350\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 30.7190 - mae: 4.2834 - val_loss: 55.2438 - val_mae: 5.3797\n",
      "Epoch 241/350\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 30.7547 - mae: 4.2552 - val_loss: 54.1387 - val_mae: 5.3910\n",
      "Epoch 242/350\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 30.7999 - mae: 4.3100 - val_loss: 55.0948 - val_mae: 5.4421\n",
      "Epoch 243/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 0s 5ms/step - loss: 30.8611 - mae: 4.2970 - val_loss: 54.6763 - val_mae: 5.3755\n",
      "Epoch 244/350\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 30.8310 - mae: 4.2506 - val_loss: 55.4140 - val_mae: 5.4555\n",
      "Epoch 245/350\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 30.9323 - mae: 4.3097 - val_loss: 54.7660 - val_mae: 5.3829\n",
      "Epoch 246/350\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 30.6327 - mae: 4.2684 - val_loss: 54.6862 - val_mae: 5.4321\n",
      "Epoch 247/350\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 30.7126 - mae: 4.2882 - val_loss: 54.5923 - val_mae: 5.3893\n",
      "Epoch 248/350\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 30.5791 - mae: 4.2548 - val_loss: 54.4821 - val_mae: 5.3988\n",
      "Epoch 249/350\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 30.6013 - mae: 4.2478 - val_loss: 54.7025 - val_mae: 5.4243\n",
      "Epoch 250/350\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 30.7560 - mae: 4.2708 - val_loss: 52.9981 - val_mae: 5.3731\n",
      "Epoch 251/350\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 30.5219 - mae: 4.2496 - val_loss: 54.7980 - val_mae: 5.4062\n",
      "Epoch 252/350\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 30.6342 - mae: 4.2647 - val_loss: 54.2118 - val_mae: 5.3709\n",
      "Epoch 253/350\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 30.6725 - mae: 4.2810 - val_loss: 53.1299 - val_mae: 5.3525\n",
      "Epoch 254/350\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 30.3804 - mae: 4.2392 - val_loss: 55.0431 - val_mae: 5.3960\n",
      "Epoch 255/350\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 30.7508 - mae: 4.2743 - val_loss: 55.5275 - val_mae: 5.4239\n",
      "Epoch 256/350\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 30.9388 - mae: 4.2821 - val_loss: 55.7400 - val_mae: 5.4796\n",
      "Epoch 257/350\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 30.5833 - mae: 4.2769 - val_loss: 55.0294 - val_mae: 5.3967\n",
      "Epoch 258/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 30.4836 - mae: 4.2617 - val_loss: 55.5606 - val_mae: 5.4256\n",
      "Epoch 259/350\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 30.4851 - mae: 4.2478 - val_loss: 56.2320 - val_mae: 5.4110\n",
      "Epoch 260/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 30.3691 - mae: 4.2408 - val_loss: 53.3412 - val_mae: 5.3480\n",
      "Epoch 261/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 30.4262 - mae: 4.2562 - val_loss: 54.1610 - val_mae: 5.3418\n",
      "Epoch 262/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 30.3142 - mae: 4.2282 - val_loss: 52.8014 - val_mae: 5.3384\n",
      "Epoch 263/350\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 30.1914 - mae: 4.2381 - val_loss: 53.6439 - val_mae: 5.3620\n",
      "Epoch 264/350\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 30.3009 - mae: 4.2462 - val_loss: 53.9382 - val_mae: 5.3680\n",
      "Epoch 265/350\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 30.2918 - mae: 4.2342 - val_loss: 54.7313 - val_mae: 5.3931\n",
      "Epoch 266/350\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 30.4303 - mae: 4.2282 - val_loss: 54.7152 - val_mae: 5.3766\n",
      "Epoch 267/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 30.0982 - mae: 4.2279 - val_loss: 56.2892 - val_mae: 5.4428\n",
      "Epoch 268/350\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 30.0984 - mae: 4.2339 - val_loss: 55.5879 - val_mae: 5.4060\n",
      "Epoch 269/350\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 29.9889 - mae: 4.2228 - val_loss: 52.8447 - val_mae: 5.3622\n",
      "Epoch 270/350\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 30.2012 - mae: 4.2542 - val_loss: 53.9948 - val_mae: 5.3629\n",
      "Epoch 271/350\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 30.2197 - mae: 4.2054 - val_loss: 54.2059 - val_mae: 5.3789\n",
      "Epoch 272/350\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 30.0134 - mae: 4.2220 - val_loss: 52.7219 - val_mae: 5.3649\n",
      "Epoch 273/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 30.2537 - mae: 4.2333 - val_loss: 53.5004 - val_mae: 5.4131\n",
      "Epoch 274/350\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 30.2995 - mae: 4.2530 - val_loss: 53.9576 - val_mae: 5.3594\n",
      "Epoch 275/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 29.9529 - mae: 4.2106 - val_loss: 53.5073 - val_mae: 5.3369\n",
      "Epoch 276/350\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 29.9680 - mae: 4.2299 - val_loss: 54.9749 - val_mae: 5.3953\n",
      "Epoch 277/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 30.1210 - mae: 4.2083 - val_loss: 53.3977 - val_mae: 5.3418\n",
      "Epoch 278/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 29.7442 - mae: 4.1909 - val_loss: 53.2115 - val_mae: 5.3429\n",
      "Epoch 279/350\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 30.2072 - mae: 4.2461 - val_loss: 53.0747 - val_mae: 5.2780\n",
      "Epoch 280/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 30.2975 - mae: 4.1980 - val_loss: 55.0168 - val_mae: 5.3939\n",
      "Epoch 281/350\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 29.8510 - mae: 4.1958 - val_loss: 54.2261 - val_mae: 5.3761\n",
      "Epoch 282/350\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 29.6358 - mae: 4.1883 - val_loss: 52.3443 - val_mae: 5.3162\n",
      "Epoch 283/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 29.9103 - mae: 4.2074 - val_loss: 54.4229 - val_mae: 5.3270\n",
      "Epoch 284/350\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 29.9858 - mae: 4.1947 - val_loss: 54.8387 - val_mae: 5.3927\n",
      "Epoch 285/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 29.5285 - mae: 4.1821 - val_loss: 53.2983 - val_mae: 5.3464\n",
      "Epoch 286/350\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 29.7250 - mae: 4.1889 - val_loss: 53.8286 - val_mae: 5.3429\n",
      "Epoch 287/350\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 29.5967 - mae: 4.1834 - val_loss: 55.0672 - val_mae: 5.3705\n",
      "Epoch 288/350\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 29.5819 - mae: 4.1729 - val_loss: 53.6978 - val_mae: 5.3592\n",
      "Epoch 289/350\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 29.6783 - mae: 4.1787 - val_loss: 53.7761 - val_mae: 5.3584\n",
      "Epoch 290/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 29.7191 - mae: 4.1770 - val_loss: 52.6592 - val_mae: 5.2881\n",
      "Epoch 291/350\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 29.6813 - mae: 4.1877 - val_loss: 54.0550 - val_mae: 5.3432\n",
      "Epoch 292/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 29.4665 - mae: 4.1491 - val_loss: 52.6109 - val_mae: 5.3547\n",
      "Epoch 293/350\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 29.7901 - mae: 4.1714 - val_loss: 53.9046 - val_mae: 5.3531\n",
      "Epoch 294/350\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 29.6657 - mae: 4.1866 - val_loss: 53.5806 - val_mae: 5.3721\n",
      "Epoch 295/350\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 29.7161 - mae: 4.1776 - val_loss: 53.7093 - val_mae: 5.3741\n",
      "Epoch 296/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 29.9071 - mae: 4.1843 - val_loss: 52.4475 - val_mae: 5.3035\n",
      "Epoch 297/350\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 29.9284 - mae: 4.2055 - val_loss: 54.3698 - val_mae: 5.3614\n",
      "Epoch 298/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 29.9845 - mae: 4.1963 - val_loss: 54.1076 - val_mae: 5.3204\n",
      "Epoch 299/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 29.5290 - mae: 4.1897 - val_loss: 55.2024 - val_mae: 5.3761\n",
      "Epoch 300/350\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 29.4473 - mae: 4.1553 - val_loss: 53.6474 - val_mae: 5.3290\n",
      "Epoch 301/350\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 29.3801 - mae: 4.1422 - val_loss: 52.4993 - val_mae: 5.3069\n",
      "Epoch 302/350\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 29.6350 - mae: 4.1937 - val_loss: 53.3656 - val_mae: 5.3030\n",
      "Epoch 303/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 29.6209 - mae: 4.2045 - val_loss: 53.9356 - val_mae: 5.3384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 304/350\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 29.6682 - mae: 4.1653 - val_loss: 54.9474 - val_mae: 5.3888\n",
      "Epoch 305/350\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 29.4126 - mae: 4.1623 - val_loss: 55.4322 - val_mae: 5.4276\n",
      "Epoch 306/350\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 29.7141 - mae: 4.1829 - val_loss: 53.9378 - val_mae: 5.3353\n",
      "Epoch 307/350\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 29.3824 - mae: 4.1696 - val_loss: 54.8069 - val_mae: 5.3344\n",
      "Epoch 308/350\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 29.5942 - mae: 4.1777 - val_loss: 54.4160 - val_mae: 5.3107\n",
      "Epoch 309/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 29.6127 - mae: 4.1697 - val_loss: 55.9631 - val_mae: 5.4253\n",
      "Epoch 310/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 29.6630 - mae: 4.1822 - val_loss: 54.7086 - val_mae: 5.3383\n",
      "Epoch 311/350\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 29.5677 - mae: 4.1775 - val_loss: 53.9564 - val_mae: 5.3274\n",
      "Epoch 312/350\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 29.3289 - mae: 4.1360 - val_loss: 52.7806 - val_mae: 5.2729\n",
      "Epoch 313/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 29.5260 - mae: 4.1747 - val_loss: 53.7655 - val_mae: 5.3246\n",
      "Epoch 314/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 29.5142 - mae: 4.1696 - val_loss: 54.8219 - val_mae: 5.3395\n",
      "Epoch 315/350\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 29.5008 - mae: 4.1399 - val_loss: 54.3629 - val_mae: 5.3289\n",
      "Epoch 316/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 29.7165 - mae: 4.1883 - val_loss: 54.5502 - val_mae: 5.3415\n",
      "Epoch 317/350\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 29.1395 - mae: 4.1484 - val_loss: 53.1657 - val_mae: 5.3137\n",
      "Epoch 318/350\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 29.3788 - mae: 4.1436 - val_loss: 52.7519 - val_mae: 5.3137\n",
      "Epoch 319/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 29.3542 - mae: 4.1588 - val_loss: 53.2761 - val_mae: 5.3320\n",
      "Epoch 320/350\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 29.3029 - mae: 4.1579 - val_loss: 53.0340 - val_mae: 5.3369\n",
      "Epoch 321/350\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 29.4798 - mae: 4.1678 - val_loss: 53.0814 - val_mae: 5.3275\n",
      "Epoch 322/350\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 29.3671 - mae: 4.1448 - val_loss: 55.0009 - val_mae: 5.3519\n",
      "Epoch 323/350\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 29.0486 - mae: 4.1280 - val_loss: 52.2117 - val_mae: 5.2712\n",
      "Epoch 324/350\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 29.5821 - mae: 4.1752 - val_loss: 54.4302 - val_mae: 5.3285\n",
      "Epoch 325/350\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 29.4579 - mae: 4.1428 - val_loss: 53.2640 - val_mae: 5.3027\n",
      "Epoch 326/350\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 29.3794 - mae: 4.1479 - val_loss: 52.7899 - val_mae: 5.3097\n",
      "Epoch 327/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 29.1088 - mae: 4.1467 - val_loss: 54.4029 - val_mae: 5.3025\n",
      "Epoch 328/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 29.3071 - mae: 4.1234 - val_loss: 54.1148 - val_mae: 5.3524\n",
      "Epoch 329/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 29.0994 - mae: 4.1362 - val_loss: 53.5499 - val_mae: 5.3131\n",
      "Epoch 330/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 29.0583 - mae: 4.1187 - val_loss: 53.6505 - val_mae: 5.3226\n",
      "Epoch 331/350\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 29.0867 - mae: 4.1279 - val_loss: 53.5056 - val_mae: 5.2988\n",
      "Epoch 332/350\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 29.3104 - mae: 4.1512 - val_loss: 53.9351 - val_mae: 5.3552\n",
      "Epoch 333/350\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 28.9112 - mae: 4.1108 - val_loss: 55.5281 - val_mae: 5.3639\n",
      "Epoch 334/350\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 29.3196 - mae: 4.1359 - val_loss: 54.1174 - val_mae: 5.3278\n",
      "Epoch 335/350\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 29.0484 - mae: 4.1106 - val_loss: 53.2553 - val_mae: 5.2790\n",
      "Epoch 336/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 29.0941 - mae: 4.1230 - val_loss: 55.5113 - val_mae: 5.3646\n",
      "Epoch 337/350\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 29.3081 - mae: 4.1492 - val_loss: 56.4613 - val_mae: 5.3869\n",
      "Epoch 338/350\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 28.9714 - mae: 4.1225 - val_loss: 55.2262 - val_mae: 5.3599\n",
      "Epoch 339/350\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 29.0385 - mae: 4.1135 - val_loss: 53.5276 - val_mae: 5.2974\n",
      "Epoch 340/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 28.9829 - mae: 4.1277 - val_loss: 53.0793 - val_mae: 5.2659\n",
      "Epoch 341/350\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 29.1587 - mae: 4.1433 - val_loss: 54.7350 - val_mae: 5.3256\n",
      "Epoch 342/350\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 29.0083 - mae: 4.1339 - val_loss: 53.6835 - val_mae: 5.3208\n",
      "Epoch 343/350\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 28.6802 - mae: 4.1030 - val_loss: 55.8345 - val_mae: 5.3526\n",
      "Epoch 344/350\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 28.9914 - mae: 4.1193 - val_loss: 54.1102 - val_mae: 5.3321\n",
      "Epoch 345/350\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 29.0098 - mae: 4.1215 - val_loss: 53.3950 - val_mae: 5.3235\n",
      "Epoch 346/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 28.9948 - mae: 4.1328 - val_loss: 54.5166 - val_mae: 5.3900\n",
      "Epoch 347/350\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 28.9741 - mae: 4.1236 - val_loss: 53.8903 - val_mae: 5.2890\n",
      "Epoch 348/350\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 28.9741 - mae: 4.1131 - val_loss: 54.2649 - val_mae: 5.3129\n",
      "Epoch 349/350\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 29.1064 - mae: 4.1323 - val_loss: 53.1681 - val_mae: 5.2666\n",
      "Epoch 350/350\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 28.9318 - mae: 4.1291 - val_loss: 53.5961 - val_mae: 5.2815\n"
     ]
    }
   ],
   "source": [
    "model1=build_model1()\n",
    "history=model1.fit(x_train, y_train, epochs=350, batch_size=8, validation_split=0.2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 2ms/step - loss: 40.8833 - mae: 4.6931\n"
     ]
    }
   ],
   "source": [
    "test_mse_score, test_mae_score = model1.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=model1.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate=pd.DataFrame({'Actual': y_test['Concrete compressive strength(MPa, megapascals) ']})\n",
    "evaluate['prediction']= pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>26.06</td>\n",
       "      <td>30.323837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>10.35</td>\n",
       "      <td>9.242197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>79.30</td>\n",
       "      <td>74.409264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>828</th>\n",
       "      <td>74.99</td>\n",
       "      <td>71.431488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>713</th>\n",
       "      <td>9.69</td>\n",
       "      <td>10.286477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>72.99</td>\n",
       "      <td>76.923721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>28.63</td>\n",
       "      <td>37.077427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>11.39</td>\n",
       "      <td>9.589267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>20.08</td>\n",
       "      <td>16.969934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>48.28</td>\n",
       "      <td>38.489132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>309 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Actual  prediction\n",
       "747   26.06   30.323837\n",
       "718   10.35    9.242197\n",
       "175   79.30   74.409264\n",
       "828   74.99   71.431488\n",
       "713    9.69   10.286477\n",
       "..      ...         ...\n",
       "156   72.99   76.923721\n",
       "222   28.63   37.077427\n",
       "665   11.39    9.589267\n",
       "210   20.08   16.969934\n",
       "306   48.28   38.489132\n",
       "\n",
       "[309 rows x 2 columns]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
