{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BXgJ6uT1NydQ"
   },
   "source": [
    "Assignment: Flowers Recognition <br>\n",
    "Dataset Description:<br>\n",
    "\n",
    "This dataset contains 4242 images of flowers.<br>\n",
    "The data collection is based on the data flicr, google images, yandex images.<br>\n",
    "You can use this datastet to recognize plants from the photo.<br>\n",
    "\n",
    "Attribute Information:<br>\n",
    "The pictures are divided into five classes: chamomile, tulip, rose, sunflower, dandelion.<br>\n",
    "For each class there are about 800 photos. Photos are not high resolution, about 320x240 pixels. <br>\n",
    "<b>Also explore how to resize images in tensorflow and then resize all the images to a same size. </b> <br>\n",
    "This is a Multiclass Classification Problem.<br>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T7vy-ktuOKJH"
   },
   "source": [
    "WORKFLOW : <br>\n",
    "Load Data <br>\n",
    "Split into 60 and 40 ratio.<br>\n",
    "Encode labels.<br>\n",
    "Create Model<br>\n",
    "Compilation Step (Note : Its a Multiclass Classification problem , select loss , metrics according to it)<br>\n",
    "Train the Model.<br>\n",
    "If the model gets overfit tune your model by changing the units , No. of layers , epochs , add dropout layer or add Regularizer according to the need .<br>\n",
    "Prediction should be > 85%<br>\n",
    "Evaluation Step<br>\n",
    "Prediction<br>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ri3Bg5qfPRic"
   },
   "source": [
    "Data : <br>\n",
    "https://drive.google.com/file/d/1-OX6wn5gA-bJpjPNfSyaYQLz-A-AB_uj/view?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "hTtg3WuGTA1o"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os \n",
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=\"C:/Users/Qutaiba/Assignment Q2/DeepLearning/flowers\"\n",
    "categories= [ \"tulip\", \"rose\", \"sunflower\", \"dandelion\", \"daisy\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = []\n",
    "img_size=100\n",
    "def create_training_data():\n",
    "    for category in categories:  \n",
    "\n",
    "        path = os.path.join(data,category)  \n",
    "        class_num = categories.index(category) \n",
    "\n",
    "        for img in os.listdir(path): \n",
    "            try:\n",
    "                img_array = cv.imread(os.path.join(path,img) ,cv.IMREAD_GRAYSCALE) \n",
    "                new_array = cv.resize(img_array, (img_size, img_size)) \n",
    "                training_data.append([new_array, class_num])\n",
    "            except Exception as e: \n",
    "                pass;\n",
    "          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "\n",
    "for features,label in training_data:\n",
    "    x.append(features)\n",
    "    y.append(label)\n",
    "\n",
    "x = np.array(x).reshape(-1, img_size, img_size, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(y).reshape((-1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.reshape((4323, 100 * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       ...,\n",
       "       [4],\n",
       "       [4],\n",
       "       [4]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4323, 10000)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "y = to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4323,)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.40, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2593, 10000)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2593,)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import regularizers\n",
    "from keras import models\n",
    "from keras import layers\n",
    "def build_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "\n",
    "\n",
    "\n",
    "    model.add(layers.Dense(5, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "325/325 [==============================] - 15s 45ms/step - loss: 521.7858 - accuracy: 0.2426\n",
      "Epoch 2/20\n",
      "325/325 [==============================] - 18s 56ms/step - loss: 351.9103 - accuracy: 0.2383\n",
      "Epoch 3/20\n",
      "325/325 [==============================] - 18s 55ms/step - loss: 315.9019 - accuracy: 0.2777\n",
      "Epoch 4/20\n",
      "325/325 [==============================] - 18s 57ms/step - loss: 307.6865 - accuracy: 0.2545\n",
      "Epoch 5/20\n",
      "325/325 [==============================] - 19s 57ms/step - loss: 264.2394 - accuracy: 0.2727\n",
      "Epoch 6/20\n",
      "325/325 [==============================] - 20s 60ms/step - loss: 233.9445 - accuracy: 0.2692\n",
      "Epoch 7/20\n",
      "325/325 [==============================] - 17s 51ms/step - loss: 213.2881 - accuracy: 0.2912\n",
      "Epoch 8/20\n",
      "325/325 [==============================] - 20s 60ms/step - loss: 197.7603 - accuracy: 0.2592\n",
      "Epoch 9/20\n",
      "325/325 [==============================] - 20s 63ms/step - loss: 182.9693 - accuracy: 0.27460s - loss: 185.2393 - accuracy:  - ETA: 0s - loss: 184.9678 \n",
      "Epoch 10/20\n",
      "325/325 [==============================] - 16s 49ms/step - loss: 185.0094 - accuracy: 0.2534\n",
      "Epoch 11/20\n",
      "325/325 [==============================] - 16s 49ms/step - loss: 185.6022 - accuracy: 0.2850\n",
      "Epoch 12/20\n",
      "325/325 [==============================] - 18s 56ms/step - loss: 186.0871 - accuracy: 0.26800s - loss: 184.1\n",
      "Epoch 13/20\n",
      "325/325 [==============================] - 17s 53ms/step - loss: 178.9613 - accuracy: 0.2989\n",
      "Epoch 14/20\n",
      "325/325 [==============================] - 16s 49ms/step - loss: 183.3838 - accuracy: 0.2862\n",
      "Epoch 15/20\n",
      "325/325 [==============================] - 14s 43ms/step - loss: 178.1335 - accuracy: 0.2815\n",
      "Epoch 16/20\n",
      "325/325 [==============================] - 22s 68ms/step - loss: 177.1823 - accuracy: 0.2885\n",
      "Epoch 17/20\n",
      "325/325 [==============================] - 22s 69ms/step - loss: 174.8325 - accuracy: 0.2823\n",
      "Epoch 18/20\n",
      "325/325 [==============================] - 22s 69ms/step - loss: 168.1897 - accuracy: 0.3093\n",
      "Epoch 19/20\n",
      "325/325 [==============================] - 17s 52ms/step - loss: 163.4220 - accuracy: 0.30040s - loss:\n",
      "Epoch 20/20\n",
      "325/325 [==============================] - 19s 59ms/step - loss: 160.6697 - accuracy: 0.3097\n"
     ]
    }
   ],
   "source": [
    "model=build_model()\n",
    "history = model.fit(x_train,y_train,epochs=20,batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 2s 36ms/step - loss: 224.5816 - accuracy: 0.2832\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[224.58164978027344, 0.2832369804382324]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred= model.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.reshape(-1)\n",
    "pred=np.round(pred)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test=pd.DataFrame(y_test)\n",
    "evaluate=pd.DataFrame([{'Actual': y_test}])\n",
    "evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.36      0.34       411\n",
      "           1       0.50      0.01      0.01       320\n",
      "           2       0.00      0.00      0.00       273\n",
      "           3       0.27      0.82      0.40       417\n",
      "           4       0.00      0.00      0.00       309\n",
      "\n",
      "   micro avg       0.28      0.28      0.28      1730\n",
      "   macro avg       0.22      0.24      0.15      1730\n",
      "weighted avg       0.23      0.28      0.18      1730\n",
      " samples avg       0.28      0.28      0.28      1730\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Qutaiba\\.conda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 3, 3, 0, 3, 3, 0, 3, 3, 0, 3, 3, 3, 3, 3, 3, 0, 3, 3, 3, 0, 3, 0, 3, 1, 0, 3, 0, 3, 3, 3, 3, 0, 3, 3]\n",
      "[2, 4, 3, 1, 0, 3, 3, 3, 4, 0, 1, 3, 3, 2, 4, 0, 4, 3, 3, 3, 4, 4, 3, 2, 1, 3, 1, 0, 2, 0, 2, 2, 3, 2, 0]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "pred_result = []\n",
    "for i, v in enumerate(pred):\n",
    "  pred_result.append(np.argmax(pred[i]))\n",
    "print(pred_result[:35])\n",
    "\n",
    "test_labels_result = []\n",
    "for i, v in enumerate(y_test):\n",
    "  test_labels_result.append(np.argmax(y_test[i]))\n",
    "print(test_labels_result[:35])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 490 matched flowers and there are 1240 unmatched flowers \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "matched = []\n",
    "for i, v in enumerate(test_labels_result):\n",
    "  if  pred_result[i] == test_labels_result[i]:\n",
    "    matched.append(\"Yes\")\n",
    "  else:\n",
    "    matched.append(\"No\")\n",
    "\n",
    "print(\"There are\",matched.count(\"Yes\"), \"matched flowers and there are\", matched.count(\"No\"), \"unmatched flowers \")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Flowers Recognition.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
